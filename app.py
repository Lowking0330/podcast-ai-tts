import streamlit as st
from gradio_client import Client
# ---------------------------------------------------------
# ğŸ”§ é—œéµä¿®æ­£ï¼šé©æ‡‰ MoviePy 2.0+ çš„å¯«æ³•
# ä¸å†å¾ .editor åŒ¯å…¥ï¼Œè€Œæ˜¯ç›´æ¥å¾ moviepy åŒ¯å…¥
# ---------------------------------------------------------
from moviepy import AudioFileClip, concatenate_audioclips, CompositeAudioClip, AudioArrayClip
import os
import re
import tempfile
import time
import numpy as np

# ---------------------------------------------------------
# 1. è³‡æ–™è¨­å®šèˆ‡åŸºç¤å‡½å¼
# ---------------------------------------------------------
speaker_map = {
    'è³½å¾·å…‹': ['è³½å¾·å…‹_å¾·é¹¿è°·_å¥³è²', 'è³½å¾·å…‹_éƒ½é”_å¥³è²', 'è³½å¾·å…‹_å¾·å›ºé”é›…_ç”·è²', 'è³½å¾·å…‹_å¾·å›ºé”é›…_å¥³è²'],
    'å¤ªé­¯é–£': ['å¤ªé­¯é–£_å¥³è²', 'å¤ªé­¯é–£_ç”·è²1', 'å¤ªé­¯é–£_ç”·è²2'],
    'è³½å¤': ['è³½å¤_å¥³è²'],
    'å¸ƒè¾²': ['å¸ƒè¾²_éƒ¡ç¾¤_ç”·è²', 'å¸ƒè¾²_å¡ç¾¤_ç”·è²', 'å¸ƒè¾²_å·’ç¾¤_ç”·è²', 'å¸ƒè¾²_ä¸¹ç¾¤_ç”·è²', 'å¸ƒè¾²_å“ç¾¤_å¥³è²'],
    'æ³°é›…': ['æ³°é›…_å››å­£_å¥³è²', 'æ³°é›…_è³½è€ƒåˆ©å…‹_ç”·è²', 'æ³°é›…_è¬å¤§_å¥³è²', 'æ³°é›…_æ±¶æ°´_ç”·è²', 'æ³°é›…_å®œè˜­æ¾¤æ•–åˆ©_å¥³è²', 'æ³°é›…_æ¾¤æ•–åˆ©_ç”·è²'],
    'é„’': ['é„’_å¥³è²'],
    'é­¯å‡±': ['é­¯å‡±_å¤§æ­¦_å¥³è²', 'é­¯å‡±_å¤šç´_ç”·è²', 'é­¯å‡±_æ±_å¥³è²', 'é­¯å‡±_èŒ‚æ—_ç”·è²', 'é­¯å‡±_è¬å±±_å¥³è²', 'é­¯å‡±_éœ§å°_å¥³è²'],
    'æ’ç£': ['æ’ç£_ä¸­_ç”·è²', 'æ’ç£_æ±_ç”·è²', 'æ’ç£_åŒ—_å¥³è²', 'æ’ç£_å—_å¥³è²'],
    'é›…ç¾': ['é›…ç¾_å¥³è²'],
    'å‘å—': ['å‘å—_å»ºå’Œ_å¥³è²', 'å‘å—_å—ç‹_å¥³è²', 'å‘å—_è¥¿ç¾¤_å¥³è²', 'å‘å—_çŸ¥æœ¬_å¥³è²'],
    'é‚µ': ['é‚µ_ç”·è²'],
    'å™¶ç‘ªè˜­': ['å™¶ç‘ªè˜­_å¥³è²'],
    'æ‹‰é˜¿é­¯å“‡': ['æ‹‰é˜¿é­¯å“‡_å¥³è²'],
    'æ’’å¥‡èŠé›…': ['æ’’å¥‡èŠé›…_å¥³è²'],
    'å¡é‚£å¡é‚£å¯Œ': ['å¡é‚£å¡é‚£å¯Œ_ç”·è²'],
    'é˜¿ç¾': ['é˜¿ç¾_æµ·å²¸_ç”·è²', 'é˜¿ç¾_æ†æ˜¥_å¥³è²', 'é˜¿ç¾_é¦¬è˜­_å¥³è²', 'é˜¿ç¾_å—å‹¢_å¥³è²', 'é˜¿ç¾_ç§€å§‘å·’_å¥³è²1', 'é˜¿ç¾_ç§€å§‘å·’_å¥³è²2'],
}

def clean_text(text):
    if not text: return ""
    text = text.replace("â€•", " ").replace("â€”", " ").replace("â€¦", " ")
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def bypass_client_validation(client, speaker_id):
    try:
        target_endpoints = [client.endpoints.get('/default_speaker_tts'), client.endpoints.get('/custom_speaker_tts')]
        for endpoint in target_endpoints:
            if endpoint and hasattr(endpoint, 'parameters'):
                for param in endpoint.parameters:
                    if 'enum' in param and speaker_id not in param['enum']:
                        param['enum'].append(speaker_id)
                    if 'choices' in param and speaker_id not in param['choices']:
                        param['choices'].append(speaker_id)
    except Exception:
        pass

def split_long_text(text, max_chars=150):
    chunks = re.split(r'([ã€‚.?!ï¼Ÿï¼\n])', text)
    final_chunks = []
    current_chunk = ""
    for chunk in chunks:
        if len(current_chunk) + len(chunk) < max_chars:
            current_chunk += chunk
        else:
            if current_chunk.strip():
                final_chunks.append(current_chunk.strip())
            current_chunk = chunk
    if current_chunk.strip():
        final_chunks.append(current_chunk.strip())
    return final_chunks

# ---------------------------------------------------------
# 2. ä»‹é¢åˆå§‹åŒ–
# ---------------------------------------------------------
st.set_page_config(page_title="åŸä½æ°‘æ—èª Podcast ç”Ÿæˆå™¨", layout="wide")
st.title("è‡ºç£åŸä½æ°‘æ—èª Podcast ç”Ÿæˆå™¨ ğŸ™ï¸")

if 'dialogue_list' not in st.session_state:
    st.session_state['dialogue_list'] = [
        {"tribe": "é˜¿ç¾", "speaker": "é˜¿ç¾_æµ·å²¸_ç”·è²", "text": "Nga'ay ho! (ä½ å¥½!)"}, 
        {"tribe": "å¤ªé­¯é–£", "speaker": "å¤ªé­¯é–£_å¥³è²", "text": "Embiyax su hug? (ä½ å¥½å—?)"}
    ]

# ---------------------------------------------------------
# 3. åˆ†é å®šç¾©
# ---------------------------------------------------------
tab1, tab2, tab3 = st.tabs(["å–®å¥æ¸¬è©¦ (Single)", "Podcast å°è©± (Dialogue)", "é•·æ–‡æœ‰è²æ›¸ (Audiobook)"])

# ==========================================
# åˆ†é  1: å–®å¥åŠŸèƒ½
# ==========================================
with tab1:
    st.subheader("å–®å¥èªéŸ³åˆæˆæ¸¬è©¦")
    c1, c2 = st.columns(2)
    with c1:
        s_tribe = st.selectbox("é¸æ“‡æ—ç¾¤", list(speaker_map.keys()), key="s1_tribe", index=15)
    with c2:
        s_speaker = st.selectbox("é¸æ“‡èªè€…", speaker_map[s_tribe], key="s1_speaker")
    
    s_text = st.text_area("è¼¸å…¥æ–‡å­—", height=100)
    
    if st.button("ç”Ÿæˆå–®å¥", key="btn_single"):
        text_clean = clean_text(s_text)
        if not text_clean:
            st.warning("è«‹è¼¸å…¥æ–‡å­—")
        else:
            try:
                with st.spinner("ç”Ÿæˆä¸­..."):
                    client = Client("https://hnang-kari-ai-asi-sluhay.ithuan.tw/")
                    bypass_client_validation(client, s_speaker)
                    try: client.predict(ethnicity=s_tribe, api_name="/lambda")
                    except: pass
                    result = client.predict(ref=s_speaker, gen_text_input=text_clean, api_name="/default_speaker_tts")
                    st.audio(result)
            except Exception as e:
                st.error(f"éŒ¯èª¤: {e}")

# ==========================================
# åˆ†é  2: Podcast å°è©± (é©æ‡‰æ–°ç‰ˆ MoviePy)
# ==========================================
with tab2:
    st.subheader("Podcast å°è©±è…³æœ¬ç·¨è¼¯å™¨")
    
    with st.expander("âš¡ å¿«é€ŸåŠ‡æœ¬åŒ¯å…¥ (å¤§é‡è¼¸å…¥å°ˆç”¨)", expanded=False):
        st.caption("è¨­å®šå¥½è§’è‰²ä»£è™Ÿ (A, B)ï¼Œç›´æ¥è²¼ä¸Šå°è©±ã€‚")
        c_role1, c_role2 = st.columns(2)
        with c_role1:
            st.markdown("**ğŸ§‘â€ğŸ¦° è§’è‰² A è¨­å®š**")
            role_a_tribe = st.selectbox("A æ—ç¾¤", list(speaker_map.keys()), key="ra_t", index=15)
            role_a_spk = st.selectbox("A èªè€…", speaker_map[role_a_tribe], key="ra_s")
        with c_role2:
            st.markdown("**ğŸ‘©â€ğŸ¦± è§’è‰² B è¨­å®š**")
            role_b_tribe = st.selectbox("B æ—ç¾¤", list(speaker_map.keys()), key="rb_t", index=1)
            role_b_spk = st.selectbox("B èªè€…", speaker_map[role_b_tribe], key="rb_s")

        script_text = st.text_area("è«‹è²¼ä¸ŠåŠ‡æœ¬ (æ ¼å¼ï¼š 'A: å…§å®¹' æˆ– 'B: å…§å®¹')", height=150, placeholder="A: ä½ å¥½\nB: ä½ å¥½å—")

        c_imp1, c_imp2 = st.columns([1, 4])
        if c_imp1.button("âš¡ è§£æä¸¦åŒ¯å…¥"):
            if not script_text.strip():
                st.warning("è«‹å…ˆè¼¸å…¥åŠ‡æœ¬å…§å®¹ï¼")
            else:
                lines = script_text.split('\n')
                new_entries = []
                for line in lines:
                    line = line.strip()
                    if not line: continue
                    if line.upper().startswith("A:") or line.startswith("Aï¼š"):
                        new_entries.append({"tribe": role_a_tribe, "speaker": role_a_spk, "text": line[2:].strip()})
                    elif line.upper().startswith("B:") or line.startswith("Bï¼š"):
                        new_entries.append({"tribe": role_b_tribe, "speaker": role_b_spk, "text": line[2:].strip()})
                    else:
                        new_entries.append({"tribe": role_a_tribe, "speaker": role_a_spk, "text": line})
                st.session_state['dialogue_list'].extend(new_entries)
                st.success(f"æˆåŠŸåŒ¯å…¥ {len(new_entries)} å¥ï¼")
                st.rerun()
        if c_imp2.button("ğŸ—‘ï¸ æ¸…ç©ºåˆ—è¡¨"):
            st.session_state['dialogue_list'] = []
            st.rerun()

    st.markdown("---")

    with st.expander("ğŸµ èƒŒæ™¯éŸ³æ¨‚è¨­å®š", expanded=False):
        c_b1, c_b2 = st.columns([3, 1])
        with c_b1: bgm_file_d = st.file_uploader("ä¸Šå‚³èƒŒæ™¯éŸ³æ¨‚", type=["mp3", "wav"], key="bgm_d")
        with c_b2: bgm_vol_d = st.slider("éŸ³é‡", 0.05, 0.5, 0.15, 0.05, key="vol_d")

    for i, line in enumerate(st.session_state['dialogue_list']):
        with st.container():
            col_idx, col_tribe, col_spk, col_text, col_del = st.columns([0.5, 2, 3, 6, 0.5])
            col_idx.write(f"#{i+1}")
            try: idx_tr = list(speaker_map.keys()).index(line['tribe'])
            except: idx_tr = 0
            new_tribe = col_tribe.selectbox("æ—ç¾¤", list(speaker_map.keys()), key=f"d_tr_{i}", index=idx_tr, label_visibility="collapsed")
            avail_spks = speaker_map[new_tribe]
            try: idx_sp = avail_spks.index(line['speaker'])
            except: idx_sp = 0
            new_speaker = col_spk.selectbox("èªè€…", avail_spks, key=f"d_sp_{i}", index=idx_sp, label_visibility="collapsed")
            new_text = col_text.text_input("å°è©", value=line['text'], key=f"d_tx_{i}", label_visibility="collapsed")
            if col_del.button("âŒ", key=f"d_dl_{i}"):
                st.session_state['dialogue_list'].pop(i)
                st.rerun()
            st.session_state['dialogue_list'][i].update({'tribe': new_tribe, 'speaker': new_speaker, 'text': new_text})

    c_add, c_run = st.columns([1, 4])
    if c_add.button("â• æ‰‹å‹•æ–°å¢"):
        last = st.session_state['dialogue_list'][-1] if st.session_state['dialogue_list'] else {"tribe": "é˜¿ç¾", "speaker": "é˜¿ç¾_æµ·å²¸_ç”·è²", "text": ""}
        st.session_state['dialogue_list'].append(last.copy())
        st.rerun()

    if c_run.button("ğŸ™ï¸ é–‹å§‹åˆæˆ Podcast", type="primary"):
        dialogue = st.session_state['dialogue_list']
        if not dialogue:
            st.warning("è…³æœ¬æ˜¯ç©ºçš„ï¼")
        else:
            progress_bar = st.progress(0)
            status_text = st.empty()
            audio_clips = []
            
            try:
                client = Client("https://hnang-kari-ai-asi-sluhay.ithuan.tw/")
                for idx, item in enumerate(dialogue):
                    txt = clean_text(item['text'])
                    spk = item['speaker']
                    trb = item['tribe']
                    if not txt: continue 
                    
                    status_text.text(f"æ­£åœ¨åˆæˆç¬¬ {idx+1}/{len(dialogue)} å¥...")
                    bypass_client_validation(client, spk)
                    try: client.predict(ethnicity=trb, api_name="/lambda")
                    except: pass
                    
                    audio_path = client.predict(ref=spk, gen_text_input=txt, api_name="/default_speaker_tts")
                    
                    clip = AudioFileClip(audio_path)
                    audio_clips.append(clip)
                    
                    # ğŸ’¡ ä¿®æ­£å¾Œçš„æ ¸å¿ƒï¼šé©æ‡‰ MoviePy 2.0 çš„ AudioArrayClip åƒæ•¸
                    # 2.0 ç‰ˆæœ¬è¦æ±‚ï¼šAudioArrayClip(array, fps=44100)
                    ch = clip.nchannels 
                    silence_array = np.zeros((int(44100 * 1.0), ch))
                    silence = AudioArrayClip(silence_array, fps=44100)
                    audio_clips.append(silence)
                    
                    progress_bar.progress((idx + 1) / len(dialogue))

                if audio_clips:
                    status_text.text("æ¥åˆä¸­...")
                    voice_track = concatenate_audioclips(audio_clips)
                    
                    final_output = voice_track
                    if bgm_file_d is not None:
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp_bgm:
                            tmp_bgm.write(bgm_file_d.getvalue())
                            tmp_bgm_path = tmp_bgm.name
                        music_track = AudioFileClip(tmp_bgm_path)
                        # BGM è™•ç†
                        if music_track.duration < voice_track.duration:
                            n_loops = int(voice_track.duration / music_track.duration) + 1
                            music_track = concatenate_audioclips([music_track] * n_loops)
                        music_track = music_track.subclip(0, voice_track.duration + 1)
                        # MoviePy 2.0 å¯èƒ½æ›´æ”¹äº† volumexï¼Œå»ºè­°ç”¨ multiply_volume æˆ–ç›´æ¥ä¹˜æ³•
                        # é€™è£¡ä½¿ç”¨æœ€é€šç”¨çš„æ–¹æ³•
                        music_track = music_track.with_volume_scaled(bgm_vol_d)
                        
                        final_output = CompositeAudioClip([music_track, voice_track])
                        os.remove(tmp_bgm_path)
                    
                    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
                    final_output.write_audiofile(temp_file.name, logger=None, fps=44100)
                    
                    for c in audio_clips: c.close()
                    final_output.close()
                    
                    st.success("ğŸ‰ Podcast å®Œæˆï¼")
                    st.audio(temp_file.name, format="audio/mp3")
                    with open(temp_file.name, "rb") as f:
                        st.download_button("ğŸ“¥ ä¸‹è¼‰ MP3", f, "podcast_final.mp3", "audio/mp3")

            except Exception as e:
                st.error(f"éŒ¯èª¤: {e}")

# ==========================================
# åˆ†é  3: é•·æ–‡æœ‰è²æ›¸ (é©æ‡‰æ–°ç‰ˆ MoviePy)
# ==========================================
with tab3:
    st.subheader("é•·æ–‡æœ‰è²æ›¸è£½ä½œ")
    c_l1, c_l2 = st.columns(2)
    with c_l1: long_tribe = st.selectbox("æœ—è®€æ—ç¾¤", list(speaker_map.keys()), key="l_tr", index=15)
    with c_l2: long_speaker = st.selectbox("æœ—è®€èªè€…", speaker_map[long_tribe], key="l_sp")
        
    long_text = st.text_area("è²¼ä¸Šé•·æ–‡ (è‡ªå‹•åˆ‡åˆ†)", height=250)
    
    with st.expander("ğŸµ èƒŒæ™¯éŸ³æ¨‚è¨­å®š", expanded=True):
        c_b3, c_b4 = st.columns([3, 1])
        with c_b3: bgm_file_l = st.file_uploader("ä¸Šå‚³éŸ³æ¨‚", type=["mp3", "wav"], key="bgm_l")
        with c_b4: bgm_vol_l = st.slider("éŸ³é‡", 0.05, 0.5, 0.15, 0.05, key="vol_l")

    if st.button("ğŸ“– é–‹å§‹è£½ä½œ", type="primary"):
        if not long_text.strip():
            st.warning("è«‹å…ˆè¼¸å…¥æ–‡å­—")
        else:
            chunks = split_long_text(clean_text(long_text), 120)
            st.info(f"å·²åˆ‡åˆ†ç‚º {len(chunks)} æ®µï¼Œé–‹å§‹åˆæˆ...")
            
            prog = st.progress(0)
            stat = st.empty()
            clips_l = []
            
            try:
                client = Client("https://hnang-kari-ai-asi-sluhay.ithuan.tw/")
                try: client.predict(ethnicity=long_tribe, api_name="/lambda")
                except: pass
                bypass_client_validation(client, long_speaker)

                for idx, chunk in enumerate(chunks):
                    stat.text(f"åˆæˆç¬¬ {idx+1}/{len(chunks)} æ®µ...")
                    path = client.predict(ref=long_speaker, gen_text_input=chunk, api_name="/default_speaker_tts")
                    
                    clip = AudioFileClip(path)
                    clips_l.append(clip)
                    
                    # åŠ å…¥ 1 ç§’éœéŸ³
                    ch = clip.nchannels 
                    silence_array = np.zeros((int(44100 * 1.0), ch))
                    silence = AudioArrayClip(silence_array, fps=44100)
                    clips_l.append(silence)
                    
                    time.sleep(0.5)
                    prog.progress((idx + 1) / len(chunks))
                
                if clips_l:
                    stat.text("æ¥åˆä¸­...")
                    voice_trk = concatenate_audioclips(clips_l)
                    final_out = voice_trk
                    
                    if bgm_file_l:
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp:
                            tmp.write(bgm_file_l.getvalue())
                            tmppath = tmp.name
                        mtrk = AudioFileClip(tmppath)
                        if mtrk.duration < voice_trk.duration:
                            nl = int(voice_trk.duration / mtrk.duration) + 1
                            mtrk = concatenate_audioclips([mtrk]*nl)
                        mtrk = mtrk.subclip(0, voice_trk.duration + 1).with_volume_scaled(bgm_vol_l)
                        final_out = CompositeAudioClip([mtrk, voice_trk])
                        os.remove(tmppath)

                    tmpf = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
                    final_out.write_audiofile(tmpf.name, logger=None, fps=44100)
                    
                    for c in clips_l: c.close()
                    final_out.close()
                    
                    st.success("ğŸ‰ æœ‰è²æ›¸å®Œæˆï¼")
                    st.audio(tmpf.name, format="audio/mp3")
                    with open(tmpf.name, "rb") as f:
                        st.download_button("ğŸ“¥ ä¸‹è¼‰æœ‰è²æ›¸", f, "audiobook_final.mp3", "audio/mp3")

            except Exception as e:
                st.error(f"éŒ¯èª¤: {e}")
