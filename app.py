import streamlit as st
from gradio_client import Client
from moviepy import AudioFileClip, concatenate_audioclips, CompositeAudioClip, AudioArrayClip
import os
import re
import tempfile
import time
import numpy as np
import json
import subprocess
import sys
from gtts import gTTS
import pandas as pd
import io

# ---------------------------------------------------------
# 1. è³‡æ–™è¨­å®šèˆ‡åŸºç¤å‡½å¼
# ---------------------------------------------------------
speaker_map = {
    'é˜¿ç¾': ['é˜¿ç¾_æµ·å²¸_ç”·è²', 'é˜¿ç¾_æ†æ˜¥_å¥³è²', 'é˜¿ç¾_é¦¬è˜­_å¥³è²', 'é˜¿ç¾_å—å‹¢_å¥³è²', 'é˜¿ç¾_ç§€å§‘å·’_å¥³è²1', 'é˜¿ç¾_ç§€å§‘å·’_å¥³è²2'],
    'æ³°é›…': ['æ³°é›…_å››å­£_å¥³è²', 'æ³°é›…_è³½è€ƒåˆ©å…‹_ç”·è²', 'æ³°é›…_è¬å¤§_å¥³è²', 'æ³°é›…_æ±¶æ°´_ç”·è²', 'æ³°é›…_å®œè˜­æ¾¤æ•–åˆ©_å¥³è²', 'æ³°é›…_æ¾¤æ•–åˆ©_ç”·è²'],
    'æ’ç£': ['æ’ç£_ä¸­_ç”·è²', 'æ’ç£_æ±_ç”·è²', 'æ’ç£_åŒ—_å¥³è²', 'æ’ç£_å—_å¥³è²'],
    'å¸ƒè¾²': ['å¸ƒè¾²_éƒ¡ç¾¤_ç”·è²', 'å¸ƒè¾²_å¡ç¾¤_ç”·è²', 'å¸ƒè¾²_å·’ç¾¤_ç”·è²', 'å¸ƒè¾²_ä¸¹ç¾¤_ç”·è²', 'å¸ƒè¾²_å“ç¾¤_å¥³è²'],
    'å¤ªé­¯é–£': ['å¤ªé­¯é–£_å¥³è²', 'å¤ªé­¯é–£_ç”·è²1', 'å¤ªé­¯é–£_ç”·è²2'],
    'è³½å¾·å…‹': ['è³½å¾·å…‹_å¾·é¹¿è°·_å¥³è²', 'è³½å¾·å…‹_éƒ½é”_å¥³è²', 'è³½å¾·å…‹_å¾·å›ºé”é›…_ç”·è²', 'è³½å¾·å…‹_å¾·å›ºé”é›…_å¥³è²'],
    'é­¯å‡±': ['é­¯å‡±_å¤§æ­¦_å¥³è²', 'é­¯å‡±_å¤šç´_ç”·è²', 'é­¯å‡±_æ±_å¥³è²', 'é­¯å‡±_èŒ‚æ—_ç”·è²', 'é­¯å‡±_è¬å±±_å¥³è²', 'é­¯å‡±_éœ§å°_å¥³è²'],
    'å‘å—': ['å‘å—_å»ºå’Œ_å¥³è²', 'å‘å—_å—ç‹_å¥³è²', 'å‘å—_è¥¿ç¾¤_å¥³è²', 'å‘å—_çŸ¥æœ¬_å¥³è²'],
    'é„’': ['é„’_å¥³è²'],
    'è³½å¤': ['è³½å¤_å¥³è²'],
    'é›…ç¾': ['é›…ç¾_å¥³è²'],
    'é‚µ': ['é‚µ_ç”·è²'],
    'å™¶ç‘ªè˜­': ['å™¶ç‘ªè˜­_å¥³è²'],
    'æ‹‰é˜¿é­¯å“‡': ['æ‹‰é˜¿é­¯å“‡_å¥³è²'],
    'æ’’å¥‡èŠé›…': ['æ’’å¥‡èŠé›…_å¥³è²'],
    'å¡é‚£å¡é‚£å¯Œ': ['å¡é‚£å¡é‚£å¯Œ_ç”·è²'],
}

def clean_text(text):
    if not text: return ""
    text = text.replace("ï¼Œ", ",").replace("ã€‚", ".").replace("ï¼Ÿ", "?").replace("ï¼", "!")
    text = text.replace("ï¼š", ":").replace("ï¼›", ";").replace("ï¼ˆ", "(").replace("ï¼‰", ")")
    text = text.replace("â€•", " ").replace("â€”", " ").replace("â€¦", " ")
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def bypass_client_validation(client, speaker_id):
    try:
        target_endpoints = [client.endpoints.get('/default_speaker_tts'), client.endpoints.get('/custom_speaker_tts')]
        for endpoint in target_endpoints:
            if endpoint and hasattr(endpoint, 'parameters'):
                for param in endpoint.parameters:
                    if 'enum' in param and speaker_id not in param['enum']:
                        param['enum'].append(speaker_id)
                    if 'choices' in param and speaker_id not in param['choices']:
                        param['choices'].append(speaker_id)
    except Exception:
        pass

def split_long_text(text, max_chars=150):
    chunks = re.split(r'([ã€‚.?!ï¼Ÿï¼\n])', text)
    final_chunks = []
    current_chunk = ""
    for chunk in chunks:
        if len(current_chunk) + len(chunk) < max_chars:
            current_chunk += chunk
        else:
            if current_chunk.strip():
                final_chunks.append(current_chunk.strip())
            current_chunk = chunk
    if current_chunk.strip():
        final_chunks.append(current_chunk.strip())
    return final_chunks

def generate_chinese_audio_subprocess(text, gender, output_path):
    voice = "zh-TW-HsiaoChenNeural" if gender == "å¥³è²" else "zh-TW-YunJheNeural"
    command = [
        sys.executable, "-m", "edge_tts",
        "--text", text,
        "--voice", voice,
        "--write-media", output_path
    ]
    try:
        subprocess.run(command, check=True, capture_output=True)
        return True
    except:
        try:
            tts = gTTS(text=text, lang='zh-tw')
            tts.save(output_path)
            return False
        except: return False

def synthesize_indigenous_speech(tribe, speaker, text):
    client = Client("https://hnang-kari-ai-asi-sluhay.ithuan.tw/")
    bypass_client_validation(client, speaker)
    client.predict(ethnicity=tribe, api_name="/lambda")
    time.sleep(2.0)
    path = client.predict(ref=speaker, gen_text_input=text, api_name="/default_speaker_tts")
    return path

# ---------------------------------------------------------
# Excel/Txt è™•ç†å‡½å¼
# ---------------------------------------------------------
def convert_df_to_excel(dialogue_list):
    df = pd.DataFrame(dialogue_list)
    df = df.rename(columns={'tribe': 'æ—ç¾¤', 'speaker': 'èªè€…', 'text': 'æ—èªå…§å®¹', 'zh': 'ä¸­æ–‡ç¿»è­¯'})
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='Script')
    return output.getvalue()

def convert_list_to_txt(dialogue_list):
    txt_content = ""
    for item in dialogue_list:
        zh_part = f" | {item.get('zh', '')}" if item.get('zh') else ""
        txt_content += f"{item['text']}{zh_part}\n"
    return txt_content

def parse_uploaded_file(uploaded_file):
    try:
        filename = uploaded_file.name
        new_data = []
        if filename.endswith('.xlsx'):
            df = pd.read_excel(uploaded_file)
            for _, row in df.iterrows():
                tribe = row.get('æ—ç¾¤') or row.get('tribe') or 'é˜¿ç¾'
                speaker = row.get('èªè€…') or row.get('speaker') or 'é˜¿ç¾_æµ·å²¸_ç”·è²'
                text = row.get('æ—èªå…§å®¹') or row.get('text') or ''
                zh = row.get('ä¸­æ–‡ç¿»è­¯') or row.get('zh') or ''
                if pd.notna(text) and str(text).strip():
                    new_data.append({
                        'tribe': str(tribe), 'speaker': str(speaker),
                        'text': str(text), 'zh': str(zh) if pd.notna(zh) else ""
                    })
        elif filename.endswith('.txt'):
            stringio = io.StringIO(uploaded_file.getvalue().decode("utf-8"))
            for line in stringio:
                line = line.strip()
                if not line: continue
                parts = line.split('|')
                raw = parts[0].strip()
                zh = parts[1].strip() if len(parts) > 1 else ""
                new_data.append({
                    'tribe': 'é˜¿ç¾', 'speaker': 'é˜¿ç¾_æµ·å²¸_ç”·è²',
                    'text': raw, 'zh': zh
                })
        return new_data
    except Exception as e:
        st.error(f"æª”æ¡ˆè§£æå¤±æ•—: {e}")
        return None

# ---------------------------------------------------------
# 2. ä»‹é¢åˆå§‹åŒ–
# ---------------------------------------------------------
st.set_page_config(page_title="Podcast-008 Pro", layout="wide", initial_sidebar_state="expanded")

with st.sidebar:
    st.image("https://img.icons8.com/color/96/microphone.png", width=80)
    st.title("åŸèª Podcast")
    st.markdown("### ğŸ‡¹ğŸ‡¼ è‡ºç£åŸä½æ°‘æ—èªç”Ÿæˆå™¨")
    st.markdown("---")
    st.success("âœ… ç³»çµ±ç‹€æ…‹ï¼šæ­£å¸¸")

st.title("ğŸ™ï¸ Podcast å…§å®¹ç”Ÿç”¢ä¸­å¿ƒ")
st.caption("ç‰ˆæœ¬: Podcast-008 Pro | åŠŸèƒ½ï¼šExcel å­˜å–ã€ä¸€éµç¯„ä¾‹ã€é›™èªç”·è²")

if 'dialogue_list' not in st.session_state:
    st.session_state['dialogue_list'] = []

# ---------------------------------------------------------
# 3. åˆ†é å®šç¾©
# ---------------------------------------------------------
tab1, tab2, tab3, tab4 = st.tabs([
    "ğŸ’¬ å–®å¥åˆæˆ", 
    "ğŸ§ Podcast (å…¨æ—èª)", 
    "ğŸ« Podcast (é›™èªæ•™å­¸)", 
    "ğŸ“– é•·æ–‡æœ‰è²æ›¸"
])

# ==========================================
# åˆ†é  1: å–®å¥åˆæˆ (å«ç¯„ä¾‹)
# ==========================================
with tab1:
    st.markdown("### ğŸ’¬ å–®å¥èªéŸ³æ¸¬è©¦")
    
    if st.button("âœ¨ è¼‰å…¥ç¯„ä¾‹ (æµ·å²¸é˜¿ç¾)", key="ex_single", help="å¿«é€Ÿå¡«å…¥é˜¿ç¾æ—å•å€™èª"):
        st.session_state['s1_tribe_idx'] = 0 
        st.session_state['s1_speaker_idx'] = 0 
        st.session_state['s1_text_val'] = "Nga'ay ho! Kicey kiso haw?" 
        st.rerun()

    def_tribe_idx = st.session_state.get('s1_tribe_idx', 0)
    
    with st.container(border=True):
        c1, c2 = st.columns(2)
        with c1:
            s_tribe = st.selectbox("é¸æ“‡æ—ç¾¤", list(speaker_map.keys()), key="s1_tribe", index=def_tribe_idx)
        with c2:
            avail_spks = speaker_map[s_tribe]
            def_spk_idx = st.session_state.get('s1_speaker_idx', 0)
            if def_spk_idx >= len(avail_spks): def_spk_idx = 0
            s_speaker = st.selectbox("é¸æ“‡èªè€…", avail_spks, key="s1_speaker", index=def_spk_idx)
        
        def_text = st.session_state.get('s1_text_val', "")
        s_text = st.text_area("è¼¸å…¥æ—èªæ–‡å­—", value=def_text, height=120)
        
        if st.button("ğŸ”Š ç”ŸæˆèªéŸ³", type="primary", use_container_width=True):
            if not s_text: st.warning("è«‹è¼¸å…¥æ–‡å­—")
            else:
                try:
                    with st.spinner(f"æ­£åœ¨åˆæˆ ({s_tribe})..."):
                        path = synthesize_indigenous_speech(s_tribe, s_speaker, clean_text(s_text))
                        st.audio(path)
                except Exception as e: st.error(f"éŒ¯èª¤: {e}")

# ==========================================
# å…±ç”¨å‡½å¼ï¼šPodcast åˆ—è¡¨ç·¨è¼¯å™¨ (ä¿®å¾© Duplicate ID)
# ==========================================
def render_script_editor(key_prefix):
    # --- ç¯„ä¾‹æŒ‰éˆ• ---
    if st.button("âœ¨ è¼‰å…¥ç¯„ä¾‹åŠ‡æœ¬ (æµ·å²¸é˜¿ç¾)", key=f"{key_prefix}_ex", use_container_width=True):
        st.session_state['dialogue_list'] = [
            {"tribe": "é˜¿ç¾", "speaker": "é˜¿ç¾_æµ·å²¸_ç”·è²", "text": "Nga'ay ho!", "zh": "ä½ å¥½ï¼"},
            {"tribe": "é˜¿ç¾", "speaker": "é˜¿ç¾_æµ·å²¸_ç”·è²", "text": "Kicey kiso haw?", "zh": "ä½ åƒé£¯äº†å—ï¼Ÿ"},
            {"tribe": "é˜¿ç¾", "speaker": "é˜¿ç¾_æµ·å²¸_ç”·è²", "text": "Hay, kicey to kaku.", "zh": "æ˜¯çš„ï¼Œæˆ‘åƒé£½äº†ã€‚"},
            {"tribe": "é˜¿ç¾", "speaker": "é˜¿ç¾_æµ·å²¸_ç”·è²", "text": "Aray!", "zh": "è¬è¬ï¼"}
        ]
        st.rerun()

    # --- å­˜æª”å·¥å…·åˆ— ---
    with st.expander("ğŸ“‚ å°ˆæ¡ˆå­˜æª”/è®€å– (æ”¯æ´ Excel/Txt)", expanded=False):
        c_save, c_load = st.columns(2)
        with c_save:
            st.markdown("#### åŒ¯å‡º")
            if st.session_state['dialogue_list']:
                # ğŸ”§ ä¿®æ­£ï¼šåŠ ä¸Š unique key
                excel_data = convert_df_to_excel(st.session_state['dialogue_list'])
                st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel (.xlsx)", excel_data, "podcast_script.xlsx", 
                                   "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", 
                                   key=f"{key_prefix}_dl_excel") # åŠ å…¥ Key
                
                txt_data = convert_list_to_txt(st.session_state['dialogue_list'])
                st.download_button("ğŸ“¥ ä¸‹è¼‰æ–‡å­—æª” (.txt)", txt_data, "podcast_script.txt", "text/plain",
                                   key=f"{key_prefix}_dl_txt") # åŠ å…¥ Key
            else:
                st.info("åˆ—è¡¨ç‚ºç©ºï¼Œç„¡æ³•ä¸‹è¼‰")

        with c_load:
            st.markdown("#### åŒ¯å…¥")
            uploaded = st.file_uploader("ä¸Šå‚³ .xlsx æˆ– .txt", type=["xlsx", "txt"], key=f"{key_prefix}_up")
            if uploaded:
                if st.button("ç¢ºèªè¼‰å…¥æª”æ¡ˆ", key=f"{key_prefix}_load"):
                    data = parse_uploaded_file(uploaded)
                    if data:
                        st.session_state['dialogue_list'] = data
                        st.success(f"æˆåŠŸè¼‰å…¥ {len(data)} ç­†è³‡æ–™ï¼")
                        time.sleep(1)
                        st.rerun()

    # --- å¿«é€ŸåŒ¯å…¥å€ ---
    with st.expander("âš¡ å¿«é€ŸåŠ‡æœ¬è²¼ä¸Š", expanded=False):
        st.caption("è¨­å®šè§’è‰²å¾Œç›´æ¥è²¼ä¸Šã€‚")
        c_r1, c_r2 = st.columns(2)
        with c_r1:
            role_a_t = st.selectbox("A æ—ç¾¤", list(speaker_map.keys()), key=f"{key_prefix}_ra_t", index=0)
            role_a_s = st.selectbox("A èªè€…", speaker_map[role_a_t], key=f"{key_prefix}_ra_s")
        with c_r2:
            role_b_t = st.selectbox("B æ—ç¾¤", list(speaker_map.keys()), key=f"{key_prefix}_rb_t", index=0)
            role_b_s = st.selectbox("B èªè€…", speaker_map[role_b_t], key=f"{key_prefix}_rb_s")

        script_in = st.text_area("è²¼ä¸ŠåŠ‡æœ¬ (A: æ—èª | ä¸­æ–‡)", height=100, key=f"{key_prefix}_txt")
        
        if st.button("ğŸš€ è§£æä¸¦è¿½åŠ ", key=f"{key_prefix}_btn_imp"):
            if script_in.strip():
                lines = script_in.split('\n')
                new_items = []
                for line in lines:
                    line = line.strip()
                    if not line: continue
                    parts = line.split('|')
                    raw = parts[0].strip()
                    zh = parts[1].strip() if len(parts)>1 else ""
                    
                    entry = {"tribe": role_a_t, "speaker": role_a_s, "text": "", "zh": zh}
                    if raw.upper().startswith("A:") or raw.startswith("Aï¼š"):
                        entry.update({"text": raw[2:].strip(), "tribe": role_a_t, "speaker": role_a_s})
                    elif raw.upper().startswith("B:") or raw.startswith("Bï¼š"):
                        entry.update({"text": raw[2:].strip(), "tribe": role_b_t, "speaker": role_b_s})
                    else:
                        entry["text"] = raw
                    new_items.append(entry)
                st.session_state['dialogue_list'].extend(new_items)
                st.rerun()
            
    st.markdown("---")
    
    # åˆ—è¡¨é¡¯ç¤º
    if not st.session_state['dialogue_list']:
        st.info("ğŸ‘‹ åˆ—è¡¨æ˜¯ç©ºçš„ï¼Œè«‹è¼‰å…¥ç¯„ä¾‹æˆ–æ–°å¢ã€‚")

    for i, line in enumerate(st.session_state['dialogue_list']):
        with st.container(border=True):
            col_idx, col_set, col_text, col_zh, col_del = st.columns([0.3, 2.7, 3.5, 3, 0.5])
            col_idx.write(f"**#{i+1}**")
            with col_set:
                try: idx_tr = list(speaker_map.keys()).index(line['tribe'])
                except: idx_tr = 0
                nt = st.selectbox("æ—", list(speaker_map.keys()), key=f"{key_prefix}_tr_{i}", index=idx_tr, label_visibility="collapsed")
                avail = speaker_map[nt]
                try: idx_sp = avail.index(line['speaker'])
                except: idx_sp = 0
                ns = st.selectbox("èª", avail, key=f"{key_prefix}_sp_{i}", index=idx_sp, label_visibility="collapsed")
            
            ntx = col_text.text_input("æ—èª", value=line['text'], key=f"{key_prefix}_tx_{i}", label_visibility="collapsed")
            nzh = col_zh.text_input("ä¸­æ–‡", value=line.get('zh',''), key=f"{key_prefix}_zh_{i}", label_visibility="collapsed")
            
            if col_del.button("ğŸ—‘ï¸", key=f"{key_prefix}_dl_{i}"):
                st.session_state['dialogue_list'].pop(i)
                st.rerun()
            st.session_state['dialogue_list'][i].update({'tribe': nt, 'speaker': ns, 'text': ntx, 'zh': nzh})

    c_add, c_clr = st.columns([4, 1])
    if c_add.button("â• æ–°å¢ä¸€è¡Œ", key=f"{key_prefix}_add", use_container_width=True):
        last = st.session_state['dialogue_list'][-1] if st.session_state['dialogue_list'] else {"tribe": "é˜¿ç¾", "speaker": "é˜¿ç¾_æµ·å²¸_ç”·è²", "text": "", "zh": ""}
        st.session_state['dialogue_list'].append(last.copy())
        st.rerun()
    if c_clr.button("ğŸ—‘ï¸ æ¸…ç©º", key=f"{key_prefix}_clr"):
        st.session_state['dialogue_list'] = []
        st.rerun()

# ==========================================
# åˆ†é  2: Podcast I (å…¨æ—èª)
# ==========================================
with tab2:
    st.markdown("### ğŸ§ Podcast I (å…¨æ—èªæ¨¡å¼)")
    render_script_editor("p1")
    
    st.markdown("#### âš™ï¸ åˆæˆè¨­å®š")
    with st.container(border=True):
        bgm_file_1 = st.file_uploader("ğŸµ èƒŒæ™¯éŸ³æ¨‚ (BGM)", type=["mp3", "wav"], key="bgm_1")
        if bgm_file_1:
            bgm_vol_1 = st.slider("BGM éŸ³é‡", 0.05, 0.5, 0.15, 0.05, key="vol_1")
        else:
            bgm_vol_1 = 0.15

    if st.button("ğŸ™ï¸ é–‹å§‹è£½ä½œ (å…¨æ—èª)", type="primary", key="run_p1", use_container_width=True):
        dialogue = st.session_state['dialogue_list']
        if not dialogue:
            st.warning("âš ï¸ è«‹å…ˆè¼¸å…¥åŠ‡æœ¬")
        else:
            try:
                progress = st.progress(0)
                status = st.status("ğŸš€ æ­£åœ¨è£½ä½œ Podcast...", expanded=True)
                clips = []
                
                for idx, item in enumerate(dialogue):
                    txt = clean_text(item['text'])
                    if not txt: continue
                    
                    status.write(f"åˆæˆ #{idx+1}: {item['tribe']}èª...")
                    path = synthesize_indigenous_speech(item['tribe'], item['speaker'], txt)
                    
                    clip = AudioFileClip(path)
                    clips.append(clip)
                    
                    silence = AudioArrayClip(np.zeros((int(44100 * 1.0), clip.nchannels)), fps=44100)
                    clips.append(silence)
                    progress.progress((idx+1)/len(dialogue))
                
                if clips:
                    status.write("ğŸµ æ­£åœ¨é€²è¡Œæ··éŸ³...")
                    final = concatenate_audioclips(clips)
                    if bgm_file_1:
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp:
                            tmp.write(bgm_file_1.getvalue())
                            tpath = tmp.name
                        music = AudioFileClip(tpath)
                        if music.duration < final.duration:
                            music = concatenate_audioclips([music] * (int(final.duration/music.duration)+1))
                        music = music.subclipped(0, final.duration+1).with_volume_scaled(bgm_vol_1)
                        final = CompositeAudioClip([music, final])
                        os.remove(tpath)
                    
                    tf = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
                    final.write_audiofile(tf.name, logger=None, fps=44100)
                    for c in clips: c.close()
                    final.close()
                    
                    status.update(label="âœ… è£½ä½œå®Œæˆï¼", state="complete", expanded=False)
                    st.success("Podcast è£½ä½œæˆåŠŸï¼")
                    st.audio(tf.name)
                    with open(tf.name, "rb") as f:
                        st.download_button("ğŸ“¥ ä¸‹è¼‰ MP3", f, "podcast_indigenous.mp3", "audio/mp3", use_container_width=True)
            except Exception as e: st.error(f"âŒ éŒ¯èª¤: {e}")

# ==========================================
# åˆ†é  3: Podcast II (é›™èªæ•™å­¸)
# ==========================================
with tab3:
    st.markdown("### ğŸ« Podcast II (é›™èªæ•™å­¸æ¨¡å¼)")
    render_script_editor("p2")
    
    st.markdown("#### âš™ï¸ åˆæˆè¨­å®š")
    with st.container(border=True):
        c_set1, c_set2 = st.columns(2)
        with c_set1:
            bgm_file_2 = st.file_uploader("ğŸµ èƒŒæ™¯éŸ³æ¨‚ (BGM)", type=["mp3", "wav"], key="bgm_2")
            bgm_vol_2 = st.slider("BGM éŸ³é‡", 0.05, 0.5, 0.15, 0.05, key="vol_2") if bgm_file_2 else 0.15
        with c_set2:
            st.markdown("**ğŸ—£ï¸ ä¸­æ–‡èªéŸ³è¨­å®š**")
            zh_gender = st.radio("é…éŸ³å“¡æ€§åˆ¥", ["å¥³è² (HsiaoChen)", "ç”·è² (YunJhe)"], index=0, horizontal=True)
            zh_gender_val = "å¥³è²" if "å¥³è²" in zh_gender else "ç”·è²"
            gap_time = st.slider("ç¿»è­¯é–“éš” (ç§’)", 0.1, 2.0, 0.5)

    if st.button("ğŸ™ï¸ é–‹å§‹è£½ä½œ (é›™èªæ•™å­¸)", type="primary", key="run_p2", use_container_width=True):
        dialogue = st.session_state['dialogue_list']
        if not dialogue:
            st.warning("âš ï¸ è«‹å…ˆè¼¸å…¥åŠ‡æœ¬")
        else:
            try:
                progress = st.progress(0)
                status = st.status("ğŸš€ æ­£åœ¨è£½ä½œé›™èªæ•™æ...", expanded=True)
                clips = []
                
                for idx, item in enumerate(dialogue):
                    txt = clean_text(item['text'])
                    zh = clean_text(item.get('zh', ''))
                    if not txt: continue
                    
                    # 1. æ—èª
                    status.write(f"åˆæˆ #{idx+1} [æ—èª]...")
                    path = synthesize_indigenous_speech(item['tribe'], item['speaker'], txt)
                    clip_ind = AudioFileClip(path)
                    clips.append(clip_ind)
                    
                    # 2. ä¸­æ–‡
                    if zh:
                        status.write(f"åˆæˆ #{idx+1} [ä¸­æ–‡]...")
                        gap = AudioArrayClip(np.zeros((int(44100 * gap_time), clip_ind.nchannels)), fps=44100)
                        clips.append(gap)
                        
                        tmp_zh_path = tempfile.mktemp(suffix=".mp3")
                        success = generate_chinese_audio_subprocess(zh, zh_gender_val, tmp_zh_path)
                        
                        if success and os.path.exists(tmp_zh_path):
                            clip_zh = AudioFileClip(tmp_zh_path)
                            clips.append(clip_zh)
                        else:
                            st.warning(f"#{idx+1} ä¸­æ–‡åˆæˆä½¿ç”¨å‚™ç”¨éŸ³æº")
                            if os.path.exists(tmp_zh_path): clips.append(AudioFileClip(tmp_zh_path))
                    
                    end_gap = AudioArrayClip(np.zeros((int(44100 * 1.0), clip_ind.nchannels)), fps=44100)
                    clips.append(end_gap)
                    
                    progress.progress((idx+1)/len(dialogue))
                
                if clips:
                    status.write("ğŸµ æ­£åœ¨æ··éŸ³...")
                    final = concatenate_audioclips(clips)
                    if bgm_file_2:
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp:
                            tmp.write(bgm_file_2.getvalue())
                            tpath = tmp.name
                        music = AudioFileClip(tpath)
                        if music.duration < final.duration:
                            music = concatenate_audioclips([music] * (int(final.duration/music.duration)+1))
                        music = music.subclipped(0, final.duration+1).with_volume_scaled(bgm_vol_2)
                        final = CompositeAudioClip([music, final])
                        os.remove(tpath)
                    
                    tf = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
                    final.write_audiofile(tf.name, logger=None, fps=44100)
                    for c in clips: c.close()
                    final.close()
                    
                    status.update(label="âœ… è£½ä½œå®Œæˆï¼", state="complete", expanded=False)
                    st.success("é›™èªæ•™æè£½ä½œæˆåŠŸï¼")
                    st.audio(tf.name)
                    with open(tf.name, "rb") as f:
                        st.download_button("ğŸ“¥ ä¸‹è¼‰ MP3", f, "podcast_bilingual.mp3", "audio/mp3", use_container_width=True)
            except Exception as e: st.error(f"âŒ éŒ¯èª¤: {e}")

# ==========================================
# åˆ†é  4: é•·æ–‡æœ‰è²æ›¸
# ==========================================
with tab4:
    st.markdown("### ğŸ“– é•·æ–‡æœ‰è²æ›¸è£½ä½œ")
    
    if st.button("âœ¨ è¼‰å…¥ç¯„ä¾‹æ–‡ç«  (æµ·å²¸é˜¿ç¾)", key="ex_long", use_container_width=True):
        st.session_state['l_tribe_idx'] = 0 
        st.session_state['l_speaker_idx'] = 0 
        st.session_state['l_text_val'] = "O kakalayan no 'Amis a tamdaw.\nItini i Taywan, adihay ko kasasiromaroma no yincumin.\nNikaorira, saadihayay a tamdaw i, o 'Amis." 
        st.rerun()

    def_l_idx = st.session_state.get('l_tribe_idx', 0)
    
    with st.container(border=True):
        c_l1, c_l2 = st.columns(2)
        with c_l1: long_tribe = st.selectbox("æœ—è®€æ—ç¾¤", list(speaker_map.keys()), key="l_tr", index=def_l_idx)
        with c_l2: 
            avail = speaker_map[long_tribe]
            def_l_s_idx = st.session_state.get('l_speaker_idx', 0)
            if def_l_s_idx >= len(avail): def_l_s_idx = 0
            long_speaker = st.selectbox("æœ—è®€èªè€…", avail, key="l_sp", index=def_l_s_idx)
            
        def_l_text = st.session_state.get('l_text_val', "")
        long_text = st.text_area("è²¼ä¸Šæ–‡ç«  (è‡ªå‹•åˆ‡åˆ†)", value=def_l_text, height=200, placeholder="è«‹è²¼ä¸Šé•·ç¯‡æ•…äº‹...")
        
        c_b3, c_b4 = st.columns([3, 1])
        with c_b3: bgm_file_l = st.file_uploader("èƒŒæ™¯éŸ³æ¨‚", type=["mp3", "wav"], key="bgm_l")
        with c_b4: bgm_vol_l = st.slider("éŸ³é‡", 0.05, 0.5, 0.15, 0.05, key="vol_l")

    if st.button("ğŸ“– é–‹å§‹è£½ä½œæœ‰è²æ›¸", type="primary", use_container_width=True):
        if not long_text.strip():
            st.warning("âš ï¸ è«‹å…ˆè¼¸å…¥æ–‡å­—")
        else:
            chunks = split_long_text(clean_text(long_text), 120)
            st.info(f"â„¹ï¸ å·²åˆ‡åˆ†ç‚º {len(chunks)} å€‹æ®µè½ï¼Œé è¨ˆè€—æ™‚ {len(chunks)*4} ç§’...")
            
            progress = st.progress(0)
            status = st.status("ğŸš€ æ­£åœ¨æœ—è®€ä¸­...", expanded=True)
            clips_l = []
            
            try:
                for idx, chunk in enumerate(chunks):
                    status.write(f"æ­£åœ¨æœ—è®€ç¬¬ {idx+1}/{len(chunks)} æ®µ...")
                    path = synthesize_indigenous_speech(long_tribe, long_speaker, chunk)
                    clip = AudioFileClip(path)
                    clips_l.append(clip)
                    
                    ch = clip.nchannels 
                    silence = AudioArrayClip(np.zeros((int(44100 * 1.0), ch)), fps=44100)
                    clips_l.append(silence)
                    
                    progress.progress((idx + 1) / len(chunks))
                
                if clips_l:
                    status.write("ğŸµ æ­£åœ¨æ··éŸ³...")
                    voice_trk = concatenate_audioclips(clips_l)
                    final_out = voice_trk
                    
                    if bgm_file_l:
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp:
                            tmp.write(bgm_file_l.getvalue())
                            tmppath = tmp.name
                        mtrk = AudioFileClip(tmppath)
                        if mtrk.duration < voice_trk.duration:
                            nl = int(voice_trk.duration / mtrk.duration) + 1
                            mtrk = concatenate_audioclips([mtrk]*nl)
                        mtrk = mtrk.subclipped(0, voice_trk.duration + 1).with_volume_scaled(bgm_vol_l)
                        final_out = CompositeAudioClip([mtrk, voice_trk])
                        os.remove(tmppath)

                    tmpf = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
                    final_out.write_audiofile(tmpf.name, logger=None, fps=44100)
                    for c in clips_l: c.close()
                    final_out.close()
                    
                    status.update(label="âœ… æœ‰è²æ›¸è£½ä½œå®Œæˆï¼", state="complete", expanded=False)
                    st.audio(tmpf.name)
                    with open(tmpf.name, "rb") as f:
                        st.download_button("ğŸ“¥ ä¸‹è¼‰æœ‰è²æ›¸", f, "audiobook.mp3", "audio/mp3", use_container_width=True)
            except Exception as e:
                st.error(f"âŒ éŒ¯èª¤: {e}")
