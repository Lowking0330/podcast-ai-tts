import streamlit as st
from moviepy import AudioFileClip, concatenate_audioclips, CompositeAudioClip, AudioArrayClip
import os
import re
import tempfile
import time
import numpy as np
import subprocess
import sys
import requests
from gtts import gTTS
import pandas as pd
import io
import shutil
from gradio_client import Client as GradioClient

# ---------------------------------------------------------
# 1. è³‡æ–™è¨­å®šèˆ‡åŸºç¤å‡½å¼ 
# ---------------------------------------------------------
speaker_map = {
    'é˜¿ç¾': ['é˜¿ç¾_æµ·å²¸_ç”·è²', 'é˜¿ç¾_æ†æ˜¥_å¥³è²', 'é˜¿ç¾_é¦¬è˜­_å¥³è²', 'é˜¿ç¾_å—å‹¢_å¥³è²', 'é˜¿ç¾_ç§€å§‘å·’_å¥³è²1', 'é˜¿ç¾_ç§€å§‘å·’_å¥³è²2'],
    'æ³°é›…': ['æ³°é›…_å››å­£_å¥³è²', 'æ³°é›…_è³½è€ƒåˆ©å…‹_ç”·è²', 'æ³°é›…_è¬å¤§_å¥³è²', 'æ³°é›…_æ±¶æ°´_ç”·è²', 'æ³°é›…_å®œè˜­æ¾¤æ•–åˆ©_å¥³è²', 'æ³°é›…_æ¾¤æ•–åˆ©_ç”·è²'],
    'æ’ç£': ['æ’ç£_ä¸­_ç”·è²', 'æ’ç£_æ±_ç”·è²', 'æ’ç£_åŒ—_å¥³è²', 'æ’ç£_å—_å¥³è²'],
    'å¸ƒè¾²': ['å¸ƒè¾²_éƒ¡ç¾¤_ç”·è²', 'å¸ƒè¾²_å¡ç¾¤_ç”·è²', 'å¸ƒè¾²_å·’ç¾¤_ç”·è²', 'å¸ƒè¾²_ä¸¹ç¾¤_ç”·è²', 'å¸ƒè¾²_å“ç¾¤_å¥³è²'],
    'å¤ªé­¯é–£': ['å¤ªé­¯é–£_å¥³è²', 'å¤ªé­¯é–£_ç”·è²1', 'å¤ªé­¯é–£_ç”·è²2'],
    'è³½å¾·å…‹': ['è³½å¾·å…‹_å¾·é¹¿è°·_å¥³è²', 'è³½å¾·å…‹_éƒ½é”_å¥³è²', 'è³½å¾·å…‹_å¾·å›ºé”é›…_ç”·è²', 'è³½å¾·å…‹_å¾·å›ºé”é›…_å¥³è²'],
    'é­¯å‡±': ['é­¯å‡±_å¤§æ­¦_å¥³è²', 'é­¯å‡±_å¤šç´_ç”·è²', 'é­¯å‡±_æ±_å¥³è²', 'é­¯å‡±_èŒ‚æ—_ç”·è²', 'é­¯å‡±_è¬å±±_å¥³è²', 'é­¯å‡±_éœ§å°_å¥³è²'],
    'å‘å—': ['å‘å—_å»ºå’Œ_å¥³è²', 'å‘å—_å—ç‹_å¥³è²', 'å‘å—_è¥¿ç¾¤_å¥³è²', 'å‘å—_çŸ¥æœ¬_å¥³è²'],
    'é„’': ['é„’_å¥³è²'],
    'è³½å¤': ['è³½å¤_å¥³è²'],
    'é›…ç¾': ['é›…ç¾_å¥³è²'],
    'é‚µ': ['é‚µ_ç”·è²'],
    'å™¶ç‘ªè˜­': ['å™¶ç‘ªè˜­_å¥³è²'],
    'æ‹‰é˜¿é­¯å“‡': ['æ‹‰é˜¿é­¯å“‡_å¥³è²'],
    'æ’’å¥‡èŠé›…': ['æ’’å¥‡èŠé›…_å¥³è²'],
    'å¡é‚£å¡é‚£å¯Œ': ['å¡é‚£å¡é‚£å¯Œ_ç”·è²'],
}

def clean_text(text):
    if not text: return ""
    text = text.replace("ï¼Œ", ",").replace("ã€‚", ".").replace("ï¼Ÿ", "?").replace("ï¼", "!")
    text = text.replace("ï¼š", ":").replace("ï¼›", ";").replace("ï¼ˆ", "(").replace("ï¼‰", ")")
    text = text.replace("â€•", " ").replace("â€”", " ").replace("â€¦", " ")
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def split_long_text(text, max_chars=150):
    chunks = re.split(r'([ã€‚.?!ï¼Ÿï¼\n])', text)
    final_chunks = []
    current_chunk = ""
    for chunk in chunks:
        if len(current_chunk) + len(chunk) < max_chars:
            current_chunk += chunk
        else:
            if current_chunk.strip():
                final_chunks.append(current_chunk.strip())
            current_chunk = chunk
    if current_chunk.strip():
        final_chunks.append(current_chunk.strip())
    return final_chunks

# ---------------------------------------------------------
# ğŸ”§ æ ¸å¿ƒï¼šAzure TTS API å‡½å¼ (å®˜æ–¹ç©©å®šç‰ˆ)
# ---------------------------------------------------------
def generate_audio_azure_api(text, voice_name, api_key, region, output_path):
    if not api_key or not region:
        return False, "æœªè¨­å®š Azure Key"

    url = f"https://{region}.tts.speech.microsoft.com/cognitiveservices/v1"
    
    headers = {
        "Ocp-Apim-Subscription-Key": api_key,
        "Content-Type": "application/ssml+xml",
        "X-Microsoft-OutputFormat": "audio-16khz-128kbitrate-mono-mp3",
        "User-Agent": "StreamlitPodcastApp"
    }
    
    ssml = f"""
    <speak version='1.0' xml:lang='zh-TW'>
        <voice xml:lang='zh-TW' name='{voice_name}'>
            {text}
        </voice>
    </speak>
    """
    
    try:
        response = requests.post(url, headers=headers, data=ssml.encode('utf-8'))
        
        if response.status_code == 200:
            with open(output_path, 'wb') as f:
                f.write(response.content)
            return True, "Azure API"
        else:
            error_msg = f"Azure Error: {response.status_code} - {response.text}"
            print(error_msg)
            return False, error_msg
            
    except Exception as e:
        print(f"Connection Error: {e}")
        return False, str(e)


def generate_chinese_audio_smart(text, gender, output_path, azure_key, azure_region):
    # 1. æ±ºå®šèªè€… (Azure å®˜æ–¹ä»£è™Ÿ)
    if gender == "ç”·è²":
        voice_name = "zh-TW-YunJheNeural"
    else:
        voice_name = "zh-TW-HsiaoChenNeural"
        
    # 2. å˜—è©¦ Azure API
    if azure_key and azure_region:
        success, msg = generate_audio_azure_api(text, voice_name, azure_key, azure_region, output_path)
        if success:
            return True, "Azure"
        else:
            print(f"Azure Failed (Turning to gTTS): {msg}")
            # å¦‚æœæ˜¯ 401 (Key éŒ¯èª¤)ï¼Œåœ¨ç¶²ç«™ä¸Šé¡¯ç¤ºæç¤º
            if "401" in msg or "403" in msg:
                 st.toast("âš ï¸ Azure èªè­‰å¤±æ•—æˆ–ç„¡æ•ˆï¼Œè½‰ç‚º gTTS", icon="ğŸ”’")
            
    # 3. å‚™æ´ gTTS
    try:
        tts = gTTS(text=text, lang='zh-tw')
        tts.save(output_path)
        is_downgrade = (gender == "ç”·è²")
        return True, ("gTTS-Fallback" if is_downgrade else "gTTS")
    except Exception as e:
        return False, f"All Failed: {e}"

# åŸä½æ°‘èªéŸ³ (ç¶­æŒ Gradio Client)
def synthesize_indigenous_speech(tribe, speaker, text):
    # é€™è£¡åŠ å…¥é‡è©¦æ©Ÿåˆ¶
    max_retries = 2
    for attempt in range(max_retries):
        try:
            # ç¢ºä¿ä½¿ç”¨æ­£ç¢ºçš„ GradioClient å¼•ç”¨
            client = GradioClient("https://hnang-kari-ai-asi-sluhay.ithuan.tw/")
            
            # å˜—è©¦ç¹éæª¢æŸ¥ (ä¿æŒåŸæœ¬çš„é‚è¼¯)
            try:
                target_endpoints = [client.endpoints.get('/default_speaker_tts'), client.endpoints.get('/custom_speaker_tts')]
                for endpoint in target_endpoints:
                    if endpoint and hasattr(endpoint, 'parameters'):
                        for param in endpoint.parameters:
                            if 'enum' in param and speaker not in param['enum']:
                                param['enum'].append(speaker)
                            if 'choices' in param and speaker not in param['choices']:
                                param['choices'].append(speaker)
            except: pass

            client.predict(ethnicity=tribe, api_name="/lambda")
            time.sleep(1.0)
            path = client.predict(ref=speaker, gen_text_input=text, api_name="/default_speaker_tts")
            return path
        except Exception as e:
            if attempt == max_retries - 1:
                print(f"Indigenous TTS Failed: {e}")
                raise e
            time.sleep(2)

# ---------------------------------------------------------
# Excel/Txt è™•ç† (ä¿æŒåŸæœ‰çš„å‡½å¼)
# ---------------------------------------------------------
def convert_df_to_excel(dialogue_list):
    df = pd.DataFrame(dialogue_list)
    df = df.rename(columns={'tribe': 'æ—ç¾¤', 'speaker': 'èªè€…', 'text': 'æ—èªå…§å®¹', 'zh': 'ä¸­æ–‡ç¿»è­¯'})
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='Script')
    return output.getvalue()

def convert_list_to_txt(dialogue_list):
    txt_content = ""
    for item in dialogue_list:
        zh_part = f" | {item.get('zh', '')}" if item.get('zh') else ""
        txt_content += f"{item['text']}{zh_part}\n"
    return txt_content

def parse_uploaded_file(uploaded_file):
    try:
        filename = uploaded_file.name
        new_data = []
        default_tribe = 'é˜¿ç¾'
        default_speaker = 'é˜¿ç¾_ç§€å§‘å·’_å¥³è²1'

        if filename.endswith('.xlsx'):
            df = pd.read_excel(uploaded_file)
            for _, row in df.iterrows():
                tribe = row.get('æ—ç¾¤') or row.get('tribe') or default_tribe
                speaker = row.get('èªè€…') or row.get('speaker') or default_speaker
                text = row.get('æ—èªå…§å®¹') or row.get('text') or ''
                zh = row.get('ä¸­æ–‡ç¿»è­¯') or row.get('zh') or ''
                if pd.notna(text) and str(text).strip():
                    new_data.append({
                        'tribe': str(tribe), 'speaker': str(speaker),
                        'text': str(text), 'zh': str(zh) if pd.notna(zh) else ""
                    })
        elif filename.endswith('.txt'):
            stringio = io.StringIO(uploaded_file.getvalue().decode("utf-8"))
            for line in stringio:
                line = line.strip()
                if not line: continue
                parts = line.split('|')
                raw = parts[0].strip()
                zh = parts[1].strip() if len(parts) > 1 else ""
                new_data.append({
                    'tribe': default_tribe, 'speaker': default_speaker,
                    'text': raw, 'zh': zh
                })
        return new_data
    except Exception as e:
        st.error(f"æª”æ¡ˆè§£æå¤±æ•—: {e}")
        return None

# ---------------------------------------------------------
# 2. ä»‹é¢åˆå§‹åŒ– (æ–°å¢ Azure Key UI)
# ---------------------------------------------------------
st.set_page_config(page_title="Podcast-021 Pro", layout="wide", initial_sidebar_state="expanded")

with st.sidebar:
    st.title("ğŸ™ï¸ åŸèª Podcast")
    st.markdown("### ğŸ‡¹ğŸ‡¼ è‡ºç£åŸä½æ°‘æ—èªç”Ÿæˆå™¨")
    
    st.markdown("---")
    # >>> é€™è£¡æ’å…¥ Azure Key è¼¸å…¥ UI <<<
    st.markdown("#### ğŸ”‘ Azure è¨­å®š (é¸å¡«)")
    st.info("è«‹è¼¸å…¥ Key å’Œ Regionï¼Œä»¥å•Ÿç”¨é«˜å“è³ª Azure ç”·è²ã€‚")
    
    if 'azure_key' not in st.session_state: st.session_state['azure_key'] = ''
    if 'azure_region' not in st.session_state: st.session_state['azure_region'] = ''
    
    user_az_key = st.text_input("Azure Speech Key", value=st.session_state['azure_key'], type="password", placeholder="å¾ Azure Portal è¤‡è£½ Key 1")
    user_az_reg = st.text_input("Region (å€åŸŸ)", value=st.session_state['azure_region'], placeholder="ä¾‹å¦‚ eastasia æˆ– eastus")
    
    if user_az_key and user_az_reg:
        st.session_state['azure_key'] = user_az_key
        st.session_state['azure_region'] = user_az_reg
        st.success("âœ… Azure API å·²å•Ÿç”¨")
    else:
        st.caption("æœªè¨­å®š Azure Keyï¼Œå°‡ä½¿ç”¨ Google å‚™æ´ã€‚")
    # <<< çµæŸ Azure Key è¼¸å…¥ UI >>>
    
    st.markdown("---")
    st.markdown("### ğŸŒŸ åŠŸèƒ½ç°¡ä»‹")
    st.info("""
    **1. ğŸ’¬ å–®å¥åˆæˆ** å¿«é€Ÿæ¸¬è©¦ä¸åŒæ—ç¾¤èˆ‡èªè€…çš„ç™¼éŸ³ã€‚
    **2. ğŸ§ Podcast I (å…¨æ—èª)** è£½ä½œæ²‰æµ¸å¼æ¯èªå»£æ’­ã€‚
    **3. ğŸ« Podcast II (é›™èªæ•™å­¸)** æ”¯æ´ä¸­æ–‡ç”·/å¥³è²åˆ‡æ›ã€‚
    **4. ğŸ“– é•·æ–‡æœ‰è²æ›¸** è‡ªå‹•åˆ‡åˆ†æœ—è®€ã€‚
    """)
    st.markdown("---")
    st.success("âœ… ç³»çµ±ç‹€æ…‹ï¼šæ­£å¸¸")
    st.caption("ç‰ˆæœ¬: Podcast-Azure | æ ¸å¿ƒ: REST API")

st.title("ğŸ™ï¸ æ—èªPodcastå…§å®¹ç”¢è£½ç¨‹å¼")
st.markdown("æ‰“é€ æ‚¨çš„å°ˆå±¬åŸä½æ°‘æ—èªå»£æ’­ç¯€ç›®ï¼Œæ”¯æ´ **16æ—42èª**ã€**é›™èªæ•™å­¸** èˆ‡ **èƒŒæ™¯æ··éŸ³**ã€‚")

if 'dialogue_list' not in st.session_state:
    st.session_state['dialogue_list'] = []

# ---------------------------------------------------------
# 3. åˆ†é å®šç¾© (ä¿æŒåŸæœ‰çš„ tab4)
# ---------------------------------------------------------
tab1, tab2, tab3, tab4 = st.tabs([
    "ğŸ’¬ å–®å¥åˆæˆ", 
    "ğŸ§ Podcast (å…¨æ—èª)", 
    "ğŸ« Podcast (é›™èªæ•™å­¸)", 
    "ğŸ“– é•·æ–‡æœ‰è²æ›¸"
])

# ==========================================
# åˆ†é  1: å–®å¥åˆæˆ (ä¿æŒåŸæœ‰é‚è¼¯)
# ==========================================
with tab1:
    st.markdown("### ğŸ’¬ å–®å¥èªéŸ³æ¸¬è©¦")
    c_btn1, c_btn2 = st.columns(2)
    with c_btn1:
        if st.button("âœ¨ è¼‰å…¥ç¯„ä¾‹ (ç§€å§‘å·’é˜¿ç¾)", key="ex_single"):
            st.session_state['s1_tribe_idx'] = 0 
            st.session_state['s1_speaker_idx'] = 4 
            st.session_state['s1_text_val'] = "Nga'ay ho! Ci Panay kako." 
            st.rerun()
    with c_btn2:
        if st.button("âœ¨ è¼‰å…¥ç¯„ä¾‹ (å—æ’ç£)", key="ex_single_paiwan", use_container_width=True):
            st.session_state['s1_tribe_idx'] = 2  # æ’ç£ (åœ¨ speaker_map çš„ç¬¬3å€‹)
            st.session_state['s1_speaker_idx'] = 3  # æ’ç£_å—_å¥³è² (åœ¨åˆ—è¡¨çš„ç¬¬4å€‹)
            st.session_state['s1_text_val'] = "Djavadjavai! Ti Muni aken." # ä½ å¥½ï¼æˆ‘æ˜¯Muniã€‚
            st.rerun()
            
    def_tribe_idx = st.session_state.get('s1_tribe_idx', 0)
    with st.container(border=True):
        c1, c2 = st.columns(2)
        with c1: s_tribe = st.selectbox("é¸æ“‡æ—ç¾¤", list(speaker_map.keys()), key="s1_tribe", index=def_tribe_idx)
        with c2:
            avail_spks = speaker_map[s_tribe]
            def_spk_idx = 4 if s_tribe == 'é˜¿ç¾' else 0
            if 's1_speaker_idx' in st.session_state: def_spk_idx = st.session_state['s1_speaker_idx']
            if def_spk_idx >= len(avail_spks): def_spk_idx = 0
            s_speaker = st.selectbox("é¸æ“‡èªè€…", avail_spks, key="s1_speaker", index=def_spk_idx)
        
        def_text = st.session_state.get('s1_text_val', "")
        s_text = st.text_area("è¼¸å…¥æ—èªæ–‡å­—", value=def_text, height=120)
        
        if st.button("ğŸ”Š ç”ŸæˆèªéŸ³", type="primary", use_container_width=True):
            if not s_text: st.warning("è«‹è¼¸å…¥æ–‡å­—")
            else:
                try:
                    with st.spinner(f"æ­£åœ¨åˆæˆ ({s_tribe})..."):
                        path = synthesize_indigenous_speech(s_tribe, s_speaker, clean_text(s_text))
                        st.audio(path)
                except Exception as e: st.error(f"éŒ¯èª¤: {e}")

# ==========================================
# å…±ç”¨å‡½å¼ï¼šPodcast åˆ—è¡¨ç·¨è¼¯å™¨ (ä¿æŒåŸæœ‰é‚è¼¯)
# ==========================================
def render_script_editor(key_prefix):
    # --- ä¿®æ”¹é–‹å§‹: æ”¹ç‚ºä¸¦æ’æŒ‰éˆ• ---
    c_btn_a, c_btn_b = st.columns(2)
    with c_btn_a:
        if st.button("âœ¨ è¼‰å…¥ç¯„ä¾‹ (é˜¿ç¾)", key=f"{key_prefix}_ex_amis", use_container_width=True):
            st.session_state['dialogue_list'] = [
                {"tribe": "é˜¿ç¾", "speaker": "é˜¿ç¾_ç§€å§‘å·’_å¥³è²1", "text": "Nga'ay ho.", "zh": "ä½ å¥½ã€‚"},
                {"tribe": "é˜¿ç¾", "speaker": "é˜¿ç¾_ç§€å§‘å·’_å¥³è²1", "text": "Maolah misa'osi kiso?", "zh": "ä½ å–œæ­¡è®€æ›¸å—ï¼Ÿ"}
            ]
            st.rerun()
    with c_btn_b:
        if st.button("âœ¨ è¼‰å…¥ç¯„ä¾‹ (æ’ç£)", key=f"{key_prefix}_ex_paiwan", use_container_width=True):
            st.session_state['dialogue_list'] = [
                {"tribe": "æ’ç£", "speaker": "æ’ç£_å—_å¥³è²", "text": "Djavadjavai.", "zh": "ä½ å¥½ã€‚"},
                {"tribe": "æ’ç£", "speaker": "æ’ç£_ä¸­_ç”·è²", "text": "cuacuay ini tje ucevucevung.", "zh": "å¥½ä¹…ä¸è¦‹ã€‚"}
            ]
            st.rerun()

    with st.expander("ğŸ“‚ å°ˆæ¡ˆå­˜æª”/è®€å–", expanded=False):
        c_save, c_load = st.columns(2)
        with c_save:
            if st.session_state['dialogue_list']:
                excel_data = convert_df_to_excel(st.session_state['dialogue_list'])
                st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel", excel_data, "podcast_script.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", key=f"{key_prefix}_dl_excel", use_container_width=True)
            else: st.info("åˆ—è¡¨ç‚ºç©º")
        with c_load:
            uploaded = st.file_uploader("ä¸Šå‚³ .xlsx/.txt", type=["xlsx", "txt"], key=f"{key_prefix}_up")
            if uploaded and st.button("è¼‰å…¥", key=f"{key_prefix}_load", use_container_width=True):
                data = parse_uploaded_file(uploaded)
                if data:
                    st.session_state['dialogue_list'] = data
                    st.success("è¼‰å…¥æˆåŠŸï¼")
                    time.sleep(1)
                    st.rerun()

    with st.expander("âš¡ å¿«é€ŸåŠ‡æœ¬è²¼ä¸Š", expanded=False):
        c_r1, c_r2 = st.columns(2)
        with c_r1:
            role_a_t = st.selectbox("A æ—ç¾¤", list(speaker_map.keys()), key=f"{key_prefix}_ra_t", index=0)
            avail_a = speaker_map[role_a_t]
            role_a_s = st.selectbox("A èªè€…", avail_a, key=f"{key_prefix}_ra_s", index=0)
        with c_r2:
            role_b_t = st.selectbox("B æ—ç¾¤", list(speaker_map.keys()), key=f"{key_prefix}_rb_t", index=0)
            avail_b = speaker_map[role_b_t]
            role_b_s = st.selectbox("B èªè€…", avail_b, key=f"{key_prefix}_rb_s", index=0)

        script_in = st.text_area("è²¼ä¸ŠåŠ‡æœ¬ (A: æ—èª | ä¸­æ–‡)", height=100, key=f"{key_prefix}_txt")
        if st.button("ğŸš€ è§£æä¸¦è¿½åŠ ", key=f"{key_prefix}_btn_imp", use_container_width=True):
            if script_in.strip():
                lines = script_in.split('\n')
                new_items = []
                for line in lines:
                    line = line.strip()
                    if not line: continue
                    parts = line.split('|')
                    raw = parts[0].strip()
                    zh = parts[1].strip() if len(parts)>1 else ""
                    entry = {"tribe": role_a_t, "speaker": role_a_s, "text": "", "zh": zh}
                    if raw.upper().startswith("A:"):
                        entry.update({"text": raw[2:].strip(), "tribe": role_a_t, "speaker": role_a_s})
                    elif raw.upper().startswith("B:"):
                        entry.update({"text": raw[2:].strip(), "tribe": role_b_t, "speaker": role_b_s})
                    else: entry["text"] = raw
                    new_items.append(entry)
                st.session_state['dialogue_list'].extend(new_items)
                st.rerun()
            
    st.markdown("---")
    if not st.session_state['dialogue_list']:
        st.info("ğŸ‘‹ åˆ—è¡¨æ˜¯ç©ºçš„ã€‚")

    for i, line in enumerate(st.session_state['dialogue_list']):
        with st.container(border=True):
            col_idx, col_set, col_text, col_zh, col_del = st.columns([0.3, 2.7, 3.5, 3, 0.5])
            col_idx.write(f"**#{i+1}**")
            with col_set:
                try: idx_tr = list(speaker_map.keys()).index(line['tribe'])
                except: idx_tr = 0
                nt = st.selectbox("æ—", list(speaker_map.keys()), key=f"{key_prefix}_tr_{i}", index=idx_tr, label_visibility="collapsed")
                avail = speaker_map[nt]
                try: idx_sp = avail.index(line['speaker'])
                except: idx_sp = 0
                ns = st.selectbox("èª", avail, key=f"{key_prefix}_sp_{i}", index=idx_sp, label_visibility="collapsed")
            
            ntx = col_text.text_input("æ—èª", value=line['text'], key=f"{key_prefix}_tx_{i}", label_visibility="collapsed")
            nzh = col_zh.text_input("ä¸­æ–‡", value=line.get('zh',''), key=f"{key_prefix}_zh_{i}", label_visibility="collapsed")
            if col_del.button("ğŸ—‘ï¸", key=f"{key_prefix}_dl_{i}"):
                st.session_state['dialogue_list'].pop(i)
                st.rerun()
            st.session_state['dialogue_list'][i].update({'tribe': nt, 'speaker': ns, 'text': ntx, 'zh': nzh})

    c_add, c_clr = st.columns([4, 1])
    if c_add.button("â• æ–°å¢ä¸€è¡Œ", key=f"{key_prefix}_add", use_container_width=True):
        last = st.session_state['dialogue_list'][-1] if st.session_state['dialogue_list'] else {"tribe": "é˜¿ç¾", "speaker": "é˜¿ç¾_ç§€å§‘å·’_å¥³è²1", "text": "", "zh": ""}
        st.session_state['dialogue_list'].append(last.copy())
        st.rerun()
    if c_clr.button("ğŸ—‘ï¸ æ¸…ç©º", key=f"{key_prefix}_clr"):
        st.session_state['dialogue_list'] = []
        st.rerun()

# ==========================================
# åˆ†é  2: Podcast I (å…¨æ—èª) (ä¿æŒåŸæœ‰é‚è¼¯)
# ==========================================
with tab2:
    st.markdown("### ğŸ§ Podcast I (å…¨æ—èªæ¨¡å¼)")
    render_script_editor("p1")
    with st.container(border=True):
        bgm_file_1 = st.file_uploader("ğŸµ BGM", type=["mp3", "wav"], key="bgm_1")
        bgm_vol_1 = st.slider("éŸ³é‡", 0.05, 0.5, 0.15, 0.05, key="vol_1")
    if st.button("ğŸ™ï¸ é–‹å§‹è£½ä½œ (å…¨æ—èª)", type="primary", key="run_p1", use_container_width=True):
        dialogue = st.session_state['dialogue_list']
        if not dialogue: st.warning("âš ï¸ è«‹å…ˆè¼¸å…¥åŠ‡æœ¬")
        else:
            try:
                progress = st.progress(0)
                status = st.status("ğŸš€ è£½ä½œä¸­...", expanded=True)
                clips = []
                for idx, item in enumerate(dialogue):
                    txt = clean_text(item['text'])
                    if not txt: continue
                    status.write(f"åˆæˆ #{idx+1} {item['tribe']}...")
                    path = synthesize_indigenous_speech(item['tribe'], item['speaker'], txt)
                    clip = AudioFileClip(path)
                    clips.append(clip)
                    clips.append(AudioArrayClip(np.zeros((int(44100 * 1.0), clip.nchannels)), fps=44100))
                    progress.progress((idx+1)/len(dialogue))
                if clips:
                    status.write("ğŸµ æ··éŸ³ä¸­...")
                    final = concatenate_audioclips(clips)
                    if bgm_file_1:
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp:
                            tmp.write(bgm_file_1.getvalue())
                            tpath = tmp.name
                        music = AudioFileClip(tpath)
                        if music.duration < final.duration:
                            music = concatenate_audioclips([music] * (int(final.duration/music.duration)+1))
                        music = music.subclipped(0, final.duration+1).with_volume_scaled(bgm_vol_1)
                        final = CompositeAudioClip([music, final])
                        os.remove(tpath)
                    tf = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
                    final.write_audiofile(tf.name, logger=None, fps=44100)
                    for c in clips: c.close()
                    final.close()
                    status.update(label="âœ… å®Œæˆï¼", state="complete", expanded=False)
                    st.success("æˆåŠŸï¼")
                    st.audio(tf.name)
                    with open(tf.name, "rb") as f:
                        st.download_button("ğŸ“¥ ä¸‹è¼‰", f, "podcast_indigenous.mp3", "audio/mp3", use_container_width=True)
            except Exception as e: st.error(f"éŒ¯èª¤: {e}")

# ==========================================
# åˆ†é  3: Podcast II (é›™èªæ•™å­¸) (ä¿®æ”¹æ ¸å¿ƒé‚è¼¯)
# ==========================================
with tab3:
    st.markdown("### ğŸ« Podcast II (é›™èªæ•™å­¸æ¨¡å¼)")
    render_script_editor("p2")
    with st.container(border=True):
        c_set1, c_set2 = st.columns(2)
        with c_set1:
            bgm_file_2 = st.file_uploader("ğŸµ BGM", type=["mp3", "wav"], key="bgm_2")
            bgm_vol_2 = st.slider("BGMéŸ³é‡", 0.05, 0.5, 0.15, 0.05, key="vol_2")
        with c_set2:
            zh_gender = st.radio("ä¸­æ–‡é…éŸ³", ["å¥³è²", "ç”·è²"], index=0, horizontal=True)
            gap_time = st.slider("ç¿»è­¯é–“éš”", 0.1, 2.0, 0.5)
            
    if st.button("ğŸ™ï¸ é–‹å§‹è£½ä½œ (é›™èª)", type="primary", key="run_p2", use_container_width=True):
        dialogue = st.session_state['dialogue_list']
        if not dialogue: st.warning("âš ï¸ è«‹å…ˆè¼¸å…¥åŠ‡æœ¬")
        else:
            try:
                progress = st.progress(0)
                status = st.status("ğŸš€ è£½ä½œä¸­...", expanded=True)
                clips = []
                
                # å–å¾—å´é‚Šæ¬„è¼¸å…¥çš„ Azure è¨­å®š
                az_key = st.session_state.get('azure_key', '')
                az_reg = st.session_state.get('azure_region', '')
                
                for idx, item in enumerate(dialogue):
                    txt = clean_text(item['text'])
                    zh = clean_text(item.get('zh', ''))
                    if not txt: continue
                    
                    status.write(f"åˆæˆ #{idx+1} æ—èª...")
                    path = synthesize_indigenous_speech(item['tribe'], item['speaker'], txt)
                    clip_ind = AudioFileClip(path)
                    clips.append(clip_ind)
                    
                    if zh:
                        status.write(f"åˆæˆ #{idx+1} ä¸­æ–‡...")
                        clips.append(AudioArrayClip(np.zeros((int(44100 * gap_time), clip_ind.nchannels)), fps=44100))
                        
                        tmp_zh_path = tempfile.mktemp(suffix=".mp3")
                        # å‘¼å«æ–°çš„ Azure API æ™ºæ…§å‡½å¼
                        success, eng = generate_chinese_audio_smart(zh, zh_gender, tmp_zh_path, az_key, az_reg)
                        
                        if success and os.path.exists(tmp_zh_path):
                            clips.append(AudioFileClip(tmp_zh_path))
                            if eng == "Azure":
                                st.toast(f"âœ… #{idx+1} Azure ç”·è²æˆåŠŸ", icon="ğŸ‰")
                            elif eng == "gTTS-Fallback":
                                st.toast(f"âš ï¸ #{idx+1} é™ç´šç‚º gTTS å¥³è²", icon="â„¹ï¸")
                        else:
                            st.error(f"#{idx+1} ä¸­æ–‡åˆæˆå¤±æ•—")
                            
                    clips.append(AudioArrayClip(np.zeros((int(44100 * 1.0), clip_ind.nchannels)), fps=44100))
                    progress.progress((idx+1)/len(dialogue))
                    
                if clips:
                    status.write("ğŸµ æ··éŸ³ä¸­...")
                    final = concatenate_audioclips(clips)
                    if bgm_file_2:
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp:
                            tmp.write(bgm_file_2.getvalue())
                            tpath = tmp.name
                        music = AudioFileClip(tpath)
                        if music.duration < final.duration:
                            music = concatenate_audioclips([music] * (int(final.duration/music.duration)+1))
                        music = music.subclipped(0, final.duration+1).with_volume_scaled(bgm_vol_2)
                        final = CompositeAudioClip([music, final])
                        os.remove(tpath)
                    tf = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
                    final.write_audiofile(tf.name, logger=None, fps=44100)
                    for c in clips: c.close()
                    final.close()
                    status.update(label="âœ… å®Œæˆï¼", state="complete", expanded=False)
                    st.success("å®Œæˆï¼")
                    st.audio(tf.name)
                    with open(tf.name, "rb") as f:
                        st.download_button("ğŸ“¥ ä¸‹è¼‰", f, "podcast_bilingual.mp3", "audio/mp3", use_container_width=True)
            except Exception as e: st.error(f"éŒ¯èª¤: {e}")

# ==========================================
# åˆ†é  4: é•·æ–‡æœ‰è²æ›¸ (ä¿æŒåŸæœ‰é‚è¼¯)
# ==========================================
with tab4:
    st.markdown("### ğŸ“– é•·æ–‡æœ‰è²æ›¸è£½ä½œ")
    
    # --- ä¿®æ”¹é–‹å§‹: æ”¹ç‚ºä¸¦æ’æŒ‰éˆ• ---
    c_l_btn1, c_l_btn2 = st.columns(2)
    with c_l_btn1:
        if st.button("âœ¨ è¼‰å…¥ç¯„ä¾‹ (ç§€å§‘å·’é˜¿ç¾)", key="ex_long_amis", use_container_width=True):
            st.session_state['l_tribe_idx'] = 0 
            st.session_state['l_speaker_idx'] = 4
            st.session_state['l_text_val'] = "O kakalayan no 'Amis a tamdaw.\nItini i Taywan, adihay ko kasasiromaroma no yincumin." 
            st.rerun()
    with c_l_btn2:
        if st.button("âœ¨ è¼‰å…¥ç¯„ä¾‹ (å—æ’ç£)", key="ex_long_paiwan", use_container_width=True):
            st.session_state['l_tribe_idx'] = 2 # æ’ç£
            st.session_state['l_speaker_idx'] = 3 # æ’ç£_å—_å¥³è²
            # é€™æ˜¯æ’ç£èªç¯„ä¾‹ï¼šç°¡å–®ä»‹ç´¹
            paiwan_text = "a qata pitua se paiwan, sinan pazangal a sauzayan uta, sinan paravac uta, pinasasevalivalitan tua kinacemekeljan. \namasan lisi tua puvaljavaljaw, namayatua kadjunangan a pazangalan nua kakaveliyan."
            st.session_state['l_text_val'] = paiwan_text
            st.rerun()
    # --- ä¿®æ”¹çµæŸ ---

    def_l_idx = st.session_state.get('l_tribe_idx', 0)
    with st.container(border=True):
        c_l1, c_l2 = st.columns(2)
        with c_l1: long_tribe = st.selectbox("æœ—è®€æ—ç¾¤", list(speaker_map.keys()), key="l_tr", index=def_l_idx)
        with c_l2: 
            avail = speaker_map[long_tribe]
            def_l_s_idx = st.session_state.get('l_speaker_idx', 0)
            if 'l_speaker_idx' not in st.session_state and long_tribe=='é˜¿ç¾': def_l_s_idx = 4
            if def_l_s_idx >= len(avail): def_l_s_idx = 0
            long_speaker = st.selectbox("æœ—è®€èªè€…", avail, key="l_sp", index=def_l_s_idx)
        
        def_l_text = st.session_state.get('l_text_val', "")
        long_text = st.text_area("è²¼ä¸Šæ–‡ç«  (è‡ªå‹•åˆ‡åˆ†)", value=def_l_text, height=200)
        c_b3, c_b4 = st.columns([3, 1])
        with c_b3: bgm_file_l = st.file_uploader("BGM", type=["mp3", "wav"], key="bgm_l")
        with c_b4: bgm_vol_l = st.slider("éŸ³é‡", 0.05, 0.5, 0.15, 0.05, key="vol_l")
    
    if st.button("ğŸ“– é–‹å§‹è£½ä½œ", type="primary", use_container_width=True):
        if not long_text.strip(): st.warning("âš ï¸ è«‹å…ˆè¼¸å…¥æ–‡å­—")
        else:
            chunks = split_long_text(clean_text(long_text), 120)
            st.info(f"â„¹ï¸ åˆ‡åˆ†ç‚º {len(chunks)} æ®µ...")
            progress = st.progress(0)
            status = st.status("ğŸš€ æœ—è®€ä¸­...", expanded=True)
            clips_l = []
            try:
                for idx, chunk in enumerate(chunks):
                    status.write(f"æœ—è®€æ®µè½ {idx+1}/{len(chunks)}...")
                    path = synthesize_indigenous_speech(long_tribe, long_speaker, chunk)
                    clip = AudioFileClip(path)
                    clips_l.append(clip)
                    clips_l.append(AudioArrayClip(np.zeros((int(44100 * 1.0), clip.nchannels)), fps=44100))
                    progress.progress((idx + 1) / len(chunks))
                if clips_l:
                    status.write("ğŸµ æ··éŸ³ä¸­...")
                    voice_trk = concatenate_audioclips(clips_l)
                    final_out = voice_trk
                    if bgm_file_l:
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp:
                            tmp.write(bgm_file_l.getvalue())
                            tmppath = tmp.name
                        mtrk = AudioFileClip(tmppath)
                        if mtrk.duration < voice_trk.duration:
                            mtrk = concatenate_audioclips([mtrk]*int(voice_trk.duration/mtrk.duration+2))
                        mtrk = mtrk.subclipped(0, voice_trk.duration + 1).with_volume_scaled(bgm_vol_l)
                        final_out = CompositeAudioClip([mtrk, voice_trk])
                        os.remove(tmppath)
                    tmpf = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
                    final_out.write_audiofile(tmpf.name, logger=None, fps=44100)
                    for c in clips_l: c.close()
                    final_out.close()
                    status.update(label="âœ… å®Œæˆï¼", state="complete", expanded=False)
                    st.audio(tmpf.name)
                    with open(tmpf.name, "rb") as f:
                        st.download_button("ğŸ“¥ ä¸‹è¼‰", f, "audiobook.mp3", "audio/mp3", use_container_width=True)
            except Exception as e: st.error(f"âŒ éŒ¯èª¤: {e}")
