import streamlit as st
from gradio_client import Client
from moviepy import AudioFileClip, concatenate_audioclips, CompositeAudioClip, AudioArrayClip
import os
import re
import tempfile
import time
import numpy as np
import json
import subprocess
import sys
from gtts import gTTS
import pandas as pd
import io
import shutil
import google.generativeai as genai
import PyPDF2

# ---------------------------------------------------------
# 1. è³‡æ–™è¨­å®šèˆ‡åŸºç¤å‡½å¼
# ---------------------------------------------------------
speaker_map = {
    'é˜¿ç¾': ['é˜¿ç¾_æµ·å²¸_ç”·è²', 'é˜¿ç¾_æ†æ˜¥_å¥³è²', 'é˜¿ç¾_é¦¬è˜­_å¥³è²', 'é˜¿ç¾_å—å‹¢_å¥³è²', 'é˜¿ç¾_ç§€å§‘å·’_å¥³è²1', 'é˜¿ç¾_ç§€å§‘å·’_å¥³è²2'],
    'æ³°é›…': ['æ³°é›…_å››å­£_å¥³è²', 'æ³°é›…_è³½è€ƒåˆ©å…‹_ç”·è²', 'æ³°é›…_è¬å¤§_å¥³è²', 'æ³°é›…_æ±¶æ°´_ç”·è²', 'æ³°é›…_å®œè˜­æ¾¤æ•–åˆ©_å¥³è²', 'æ³°é›…_æ¾¤æ•–åˆ©_ç”·è²'],
    'æ’ç£': ['æ’ç£_ä¸­_ç”·è²', 'æ’ç£_æ±_ç”·è²', 'æ’ç£_åŒ—_å¥³è²', 'æ’ç£_å—_å¥³è²'],
    'å¸ƒè¾²': ['å¸ƒè¾²_éƒ¡ç¾¤_ç”·è²', 'å¸ƒè¾²_å¡ç¾¤_ç”·è²', 'å¸ƒè¾²_å·’ç¾¤_ç”·è²', 'å¸ƒè¾²_ä¸¹ç¾¤_ç”·è²', 'å¸ƒè¾²_å“ç¾¤_å¥³è²'],
    'å¤ªé­¯é–£': ['å¤ªé­¯é–£_å¥³è²', 'å¤ªé­¯é–£_ç”·è²1', 'å¤ªé­¯é–£_ç”·è²2'],
    'è³½å¾·å…‹': ['è³½å¾·å…‹_å¾·é¹¿è°·_å¥³è²', 'è³½å¾·å…‹_éƒ½é”_å¥³è²', 'è³½å¾·å…‹_å¾·å›ºé”é›…_ç”·è²', 'è³½å¾·å…‹_å¾·å›ºé”é›…_å¥³è²'],
    'é­¯å‡±': ['é­¯å‡±_å¤§æ­¦_å¥³è²', 'é­¯å‡±_å¤šç´_ç”·è²', 'é­¯å‡±_æ±_å¥³è²', 'é­¯å‡±_èŒ‚æ—_ç”·è²', 'é­¯å‡±_è¬å±±_å¥³è²', 'é­¯å‡±_éœ§å°_å¥³è²'],
    'å‘å—': ['å‘å—_å»ºå’Œ_å¥³è²', 'å‘å—_å—ç‹_å¥³è²', 'å‘å—_è¥¿ç¾¤_å¥³è²', 'å‘å—_çŸ¥æœ¬_å¥³è²'],
    'é„’': ['é„’_å¥³è²'],
    'è³½å¤': ['è³½å¤_å¥³è²'],
    'é›…ç¾': ['é›…ç¾_å¥³è²'],
    'é‚µ': ['é‚µ_ç”·è²'],
    'å™¶ç‘ªè˜­': ['å™¶ç‘ªè˜­_å¥³è²'],
    'æ‹‰é˜¿é­¯å“‡': ['æ‹‰é˜¿é­¯å“‡_å¥³è²'],
    'æ’’å¥‡èŠé›…': ['æ’’å¥‡èŠé›…_å¥³è²'],
    'å¡é‚£å¡é‚£å¯Œ': ['å¡é‚£å¡é‚£å¯Œ_ç”·è²'],
}

def clean_text(text):
    if not text: return ""
    text = text.replace("ï¼Œ", ",").replace("ã€‚", ".").replace("ï¼Ÿ", "?").replace("ï¼", "!")
    text = text.replace("ï¼š", ":").replace("ï¼›", ";").replace("ï¼ˆ", "(").replace("ï¼‰", ")")
    text = text.replace("â€•", " ").replace("â€”", " ").replace("â€¦", " ")
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def bypass_client_validation(client, speaker_id):
    try:
        target_endpoints = [client.endpoints.get('/default_speaker_tts'), client.endpoints.get('/custom_speaker_tts')]
        for endpoint in target_endpoints:
            if endpoint and hasattr(endpoint, 'parameters'):
                for param in endpoint.parameters:
                    if 'enum' in param and speaker_id not in param['enum']:
                        param['enum'].append(speaker_id)
                    if 'choices' in param and speaker_id not in param['choices']:
                        param['choices'].append(speaker_id)
    except Exception:
        pass

def split_long_text(text, max_chars=150):
    chunks = re.split(r'([ã€‚.?!ï¼Ÿï¼\n])', text)
    final_chunks = []
    current_chunk = ""
    for chunk in chunks:
        if len(current_chunk) + len(chunk) < max_chars:
            current_chunk += chunk
        else:
            if current_chunk.strip():
                final_chunks.append(current_chunk.strip())
            current_chunk = chunk
    if current_chunk.strip():
        final_chunks.append(current_chunk.strip())
    return final_chunks

def generate_chinese_audio_free_tier(text, gender, output_path):
    edge_voice = "zh-TW-HsiaoChenNeural" if gender == "å¥³è²" else "zh-TW-YunJheNeural"
    command = [
        sys.executable, "-m", "edge_tts",
        "--text", text,
        "--voice", edge_voice,
        "--write-media", output_path
    ]
    try:
        subprocess.run(command, check=True, capture_output=True, timeout=10)
        if os.path.exists(output_path) and os.path.getsize(output_path) > 0:
            return True, "Edge-TTS"
    except: pass
    
    try:
        tts = gTTS(text=text, lang='zh-tw')
        tts.save(output_path)
        is_downgrade = (gender == "ç”·è²")
        return True, ("gTTS-Fallback" if is_downgrade else "gTTS")
    except:
        return False, "Error"

def synthesize_indigenous_speech(tribe, speaker, text):
    client = Client("https://hnang-kari-ai-asi-sluhay.ithuan.tw/")
    bypass_client_validation(client, speaker)
    client.predict(ethnicity=tribe, api_name="/lambda")
    time.sleep(2.0)
    path = client.predict(ref=speaker, gen_text_input=text, api_name="/default_speaker_tts")
    return path

# ---------------------------------------------------------
# ğŸ”§ AI è…³æœ¬ç”Ÿæˆå‡½å¼ (RAG Core)
# ---------------------------------------------------------
def read_pdf(file):
    pdf_reader = PyPDF2.PdfReader(file)
    text = ""
    for page in pdf_reader.pages:
        text += page.extract_text()
    return text

def generate_script_with_gemini(api_key, context_text, topic, role_a_name="è€å¸«", role_b_name="å­¸ç”Ÿ"):
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
        
        prompt = f"""
        ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å»£æ’­åŠ‡ç·¨åŠ‡ã€‚è«‹æ ¹æ“šä»¥ä¸‹æä¾›çš„ã€Œåƒè€ƒè³‡æ–™ã€å’Œã€Œä¸»é¡Œã€ï¼Œæ’°å¯«ä¸€æ®µé›™äººå°è©±åŠ‡æœ¬ã€‚
        
        ã€åƒè€ƒè³‡æ–™ã€‘ï¼š
        {context_text[:5000]} (å…§å®¹éé•·å·²æˆªæ–·)
        
        ã€ä¸»é¡Œã€‘ï¼š{topic}
        
        ã€è§’è‰²è¨­å®šã€‘ï¼š
        - A: {role_a_name} (è² è²¬è§£èªªï¼Œä½¿ç”¨é˜¿ç¾èª)
        - B: {role_b_name} (è² è²¬æå•ï¼Œä½¿ç”¨é˜¿ç¾èª)
        
        ã€è¼¸å‡ºè¦å‰‡ã€‘ï¼š
        1. è«‹è¼¸å‡ºç´” JSON æ ¼å¼çš„åˆ—è¡¨ (List of Objects)ã€‚
        2. æ¯å€‹ç‰©ä»¶å¿…é ˆåŒ…å«å››å€‹æ¬„ä½ï¼š
           - "tribe": å›ºå®šç‚º "é˜¿ç¾"
           - "speaker": å›ºå®šç‚º "é˜¿ç¾_ç§€å§‘å·’_å¥³è²1"
           - "text": é˜¿ç¾èªå°è© (è«‹æ ¹æ“šåƒè€ƒè³‡æ–™ç¿»è­¯æˆ–å‰µä½œï¼Œç”¨ç¾…é¦¬æ‹¼éŸ³)
           - "zh": å°æ‡‰çš„ä¸­æ–‡ç¿»è­¯
        3. ä¸è¦è¼¸å‡º Markdown æ¨™è¨˜ (å¦‚ ```json)ï¼Œåªè¦ç´”æ–‡å­—çš„ JSONã€‚
        
        ã€ç¯„ä¾‹æ ¼å¼ã€‘ï¼š
        [
            {{"tribe": "é˜¿ç¾", "speaker": "é˜¿ç¾_ç§€å§‘å·’_å¥³è²1", "text": "Nga'ay ho!", "zh": "ä½ å¥½ï¼"}},
            {{"tribe": "é˜¿ç¾", "speaker": "é˜¿ç¾_ç§€å§‘å·’_å¥³è²1", "text": "Maolah misa'osi kiso?", "zh": "ä½ å–œæ­¡è®€æ›¸å—ï¼Ÿ"}}
        ]
        """
        
        response = model.generate_content(prompt)
        clean_json = response.text.strip().replace("```json", "").replace("```", "")
        return json.loads(clean_json)
        
    except Exception as e:
        raise Exception(f"AI ç”Ÿæˆå¤±æ•—: {e}")

# ---------------------------------------------------------
# 2. ä»‹é¢åˆå§‹åŒ–
# ---------------------------------------------------------
st.set_page_config(page_title="Podcast-015 AI", layout="wide", initial_sidebar_state="expanded")

with st.sidebar:
    # âœ… ä¿®æ­£é»ï¼šä½¿ç”¨ç´”ç¶²å€ï¼Œæ²’æœ‰ Markdown ç¬¦è™Ÿ
    st.image("[https://img.icons8.com/color/96/microphone.png](https://img.icons8.com/color/96/microphone.png)", width=80)
    
    st.title("åŸèª Podcast")
    st.markdown("### ğŸ‡¹ğŸ‡¼ è‡ºç£åŸä½æ°‘æ—èªç”Ÿæˆå™¨")
    
    st.markdown("---")
    st.markdown("### ğŸŒŸ åŠŸèƒ½ç°¡ä»‹ (AIç‰ˆ)")
    st.info("""
    **ğŸ§ª AIå¯¦é©—ç‰ˆåŠŸèƒ½**ï¼š
    
    **1. ğŸ¤– AI å¯«åŠ‡æœ¬** çµåˆ Google Geminiï¼Œè®€å– PDF æˆ–æ–‡å­—è³‡æ–™ï¼Œè‡ªå‹•æ’°å¯«å°è©±è…³æœ¬ã€‚
    
    **2. ğŸ™ï¸ é›™èªåˆæˆ**
    è‡ªå‹•å¸¶å…¥ç”Ÿæˆçš„è…³æœ¬é€²è¡Œåˆæˆã€‚
    """)
    
    st.markdown("---")
    st.markdown("#### ğŸ”‘ AI è¨­å®š")
    if 'gemini_key' not in st.session_state:
        st.session_state['gemini_key'] = ''
    
    user_key = st.text_input("Gemini API Key", value=st.session_state['gemini_key'], type="password")
    if user_key:
        st.session_state['gemini_key'] = user_key
        st.success("API Key å·²è¨­å®š")

    st.markdown("---")
    st.success("âœ… ç³»çµ±ç‹€æ…‹ï¼šæ­£å¸¸")

st.title("ğŸ§ª AI å¯¦é©—å®¤ï¼šæ™ºæ…§åŠ‡æœ¬ç”Ÿæˆ")
st.markdown("çµåˆ **RAG (æª¢ç´¢å¢å¼·ç”Ÿæˆ)** æŠ€è¡“ï¼Œè®“ AI è®€æ‡‚è³‡æ–™ï¼Œè‡ªå‹•ç”¢å‡ºæ—èªå»£æ’­åŠ‡ã€‚")

if 'dialogue_list' not in st.session_state:
    st.session_state['dialogue_list'] = []

# ---------------------------------------------------------
# 3. åˆ†é å®šç¾©
# ---------------------------------------------------------
tab_ai, tab_tts = st.tabs(["ğŸ¤– AI å¯«åŠ‡æœ¬ (RAG)", "ğŸ™ï¸ é–‹å§‹åˆæˆ (TTS)"])

# ==========================================
# åˆ†é  1: AI å¯«åŠ‡æœ¬ (RAG)
# ==========================================
with tab_ai:
    st.markdown("### æ­¥é©Ÿ 1ï¼šæä¾›è³‡æ–™è®“ AI å¯«åŠ‡æœ¬")
    
    api_key = st.session_state.get('gemini_key', '')
    if not api_key:
        st.warning("âš ï¸ è«‹å…ˆåœ¨å·¦å´è¼¸å…¥ Google Gemini API Key")
    
    with st.container(border=True):
        input_method = st.radio("è³‡æ–™ä¾†æº", ["è²¼ä¸Šæ–‡å­—", "ä¸Šå‚³ PDF"], horizontal=True)
        
        context_text = ""
        if input_method == "è²¼ä¸Šæ–‡å­—":
            context_text = st.text_area("åƒè€ƒè³‡æ–™", height=200, placeholder="è²¼ä¸Šéƒ¨è½æ•…äº‹ã€æ–°èæˆ–æ–‡åŒ–ä»‹ç´¹...")
        else:
            uploaded_pdf = st.file_uploader("ä¸Šå‚³ PDF", type="pdf")
            if uploaded_pdf:
                try:
                    context_text = read_pdf(uploaded_pdf)
                    st.success(f"æˆåŠŸè®€å– {len(context_text)} å­—")
                except: st.error("PDF è®€å–å¤±æ•—")
        
        c_ai1, c_ai2 = st.columns(2)
        with c_ai1:
            topic = st.text_input("åŠ‡æœ¬ä¸»é¡Œ", value="è«‹æ ¹æ“šè³‡æ–™å¯«ä¸€æ®µæ—èªæ•™å­¸å°è©±")
        with c_ai2:
            role_a = st.text_input("è§’è‰² A (è§£èªªè€…)", value="è€å¸«")
            
    if st.button("ğŸš€ AI ç”ŸæˆåŠ‡æœ¬", type="primary", disabled=not api_key, use_container_width=True):
        if not context_text:
            st.warning("è«‹æä¾›åƒè€ƒè³‡æ–™")
        else:
            try:
                with st.spinner("AI æ­£åœ¨é–±è®€ä¸¦æ’°å¯«åŠ‡æœ¬..."):
                    script_data = generate_script_with_gemini(api_key, context_text, topic, role_a_name=role_a)
                    st.session_state['dialogue_list'] = script_data
                    st.success(f"ç”ŸæˆæˆåŠŸï¼å…± {len(script_data)} å¥ã€‚")
                    st.info("ğŸ’¡ è«‹åˆ‡æ›åˆ°ã€ŒğŸ™ï¸ é–‹å§‹åˆæˆã€åˆ†é æŸ¥çœ‹çµæœã€‚")
                    with st.expander("æŸ¥çœ‹ç”Ÿæˆå…§å®¹", expanded=True):
                        st.json(script_data)
            except Exception as e:
                st.error(f"ç”Ÿæˆå¤±æ•—: {e}")

# ==========================================
# åˆ†é  2: TTS åˆæˆ (æ²¿ç”¨ Podcast II é‚è¼¯)
# ==========================================
with tab_tts:
    st.markdown("### æ­¥é©Ÿ 2ï¼šæª¢æŸ¥ä¸¦åˆæˆèªéŸ³")
    
    # ç°¡æ˜“ç·¨è¼¯å™¨
    if not st.session_state['dialogue_list']:
        st.info("ğŸ‘‹ è«‹å…ˆåœ¨ã€ŒğŸ¤– AI å¯«åŠ‡æœ¬ã€åˆ†é ç”Ÿæˆå…§å®¹ï¼Œæˆ–åœ¨æ­¤æ‰‹å‹•è¼¸å…¥ã€‚")
        
    for i, line in enumerate(st.session_state['dialogue_list']):
        with st.container(border=True):
            c1, c2, c3 = st.columns([2, 3, 3])
            c1.write(f"**#{i+1} {line['speaker'].split('_')[1]}**") # é¡¯ç¤ºèº«åˆ†
            line['text'] = c2.text_input("æ—èª", line['text'], key=f"ai_tx_{i}", label_visibility="collapsed")
            line['zh'] = c3.text_input("ä¸­æ–‡", line.get('zh',''), key=f"ai_zh_{i}", label_visibility="collapsed")

    with st.container(border=True):
        c_set1, c_set2 = st.columns(2)
        with c_set1:
            bgm_file = st.file_uploader("èƒŒæ™¯éŸ³æ¨‚ (BGM)", type=["mp3", "wav"])
            bgm_vol = st.slider("éŸ³é‡", 0.05, 0.5, 0.15, 0.05)
        with c_set2:
            zh_gender = st.radio("ä¸­æ–‡é…éŸ³", ["å¥³è²", "ç”·è²"], index=0, horizontal=True)
            gap_time = st.slider("ç¿»è­¯é–“éš”", 0.1, 2.0, 0.5)

    if st.button("ğŸ™ï¸ é–‹å§‹åˆæˆ (é›™èªæ¨¡å¼)", type="primary", use_container_width=True):
        dialogue = st.session_state['dialogue_list']
        if not dialogue: st.warning("ç„¡å…§å®¹")
        else:
            try:
                progress = st.progress(0)
                status = st.status("ğŸš€ è£½ä½œä¸­...", expanded=True)
                clips = []
                
                for idx, item in enumerate(dialogue):
                    txt = clean_text(item['text'])
                    zh = clean_text(item.get('zh', ''))
                    if not txt: continue
                    
                    status.write(f"åˆæˆ #{idx+1} [æ—èª]...")
                    path = synthesize_indigenous_speech(item['tribe'], item['speaker'], txt)
                    clip_ind = AudioFileClip(path)
                    clips.append(clip_ind)
                    
                    if zh:
                        status.write(f"åˆæˆ #{idx+1} [ä¸­æ–‡]...")
                        clips.append(AudioArrayClip(np.zeros((int(44100 * gap_time), clip_ind.nchannels)), fps=44100))
                        tmp_zh = tempfile.mktemp(suffix=".mp3")
                        success, _ = generate_chinese_audio_free_tier(zh, zh_gender, tmp_zh)
                        if success and os.path.exists(tmp_zh):
                            clips.append(AudioFileClip(tmp_zh))
                    
                    clips.append(AudioArrayClip(np.zeros((int(44100 * 1.0), clip_ind.nchannels)), fps=44100))
                    progress.progress((idx+1)/len(dialogue))
                
                if clips:
                    status.write("ğŸµ æ··éŸ³ä¸­...")
                    final = concatenate_audioclips(clips)
                    if bgm_file:
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp:
                            tmp.write(bgm_file.getvalue())
                            tpath = tmp.name
                        music = AudioFileClip(tpath)
                        if music.duration < final.duration:
                            music = concatenate_audioclips([music] * (int(final.duration/music.duration)+1))
                        music = music.subclipped(0, final.duration+1).with_volume_scaled(bgm_vol)
                        final = CompositeAudioClip([music, final])
                        os.remove(tpath)
                    
                    tf = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
                    final.write_audiofile(tf.name, logger=None, fps=44100)
                    for c in clips: c.close()
                    final.close()
                    
                    status.update(label="âœ… å®Œæˆï¼", state="complete", expanded=False)
                    st.audio(tf.name)
                    with open(tf.name, "rb") as f:
                        st.download_button("ğŸ“¥ ä¸‹è¼‰ MP3", f, "ai_podcast.mp3", "audio/mp3", use_container_width=True)
            except Exception as e: st.error(f"éŒ¯èª¤: {e}")
